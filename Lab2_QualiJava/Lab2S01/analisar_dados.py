import os
import logging
import pandas as pd

# Configura√ß√£o dos diret√≥rios base e da pasta de dados
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__)))
DATA_DIR = os.path.abspath(os.path.join(BASE_DIR, 'data'))

# Configura√ß√£o do logger
script_dir = os.path.dirname(os.path.abspath(__file__))
LOG_DIR = os.path.join(script_dir, "Relat√≥rios")
LOG_FILE = os.path.join(LOG_DIR, "analisar_dados_log.log")
os.makedirs(LOG_DIR, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)-8s - %(message)s",
    handlers=[logging.StreamHandler(), logging.FileHandler(LOG_FILE, encoding="utf-8")]
)

def verificar_arquivo_entrada():
    input_file = os.path.join(DATA_DIR, 'resultados_totais.csv')
    logging.info("üîç Verificando exist√™ncia e integridade do arquivo de entrada...")

    if not os.path.exists(input_file):
        logging.error(f"‚ùå Arquivo n√£o encontrado: {input_file}")
        raise FileNotFoundError(f"‚ùå Arquivo n√£o encontrado: {input_file}")

    if os.stat(input_file).st_size == 0:
        logging.warning(f"‚ö†Ô∏è Arquivo vazio encontrado: {input_file}")
        return None

    logging.info(f"‚úÖ Arquivo de entrada verificado com sucesso: {input_file}")
    return input_file

def analisar_dados(input_file):
    logging.info("üìä Iniciando an√°lise dos dados coletados...")
    output_file = os.path.join(DATA_DIR, 'analise_metrica_ck.csv')

    try:
        df = pd.read_csv(input_file)
        logging.info(f"üì• Arquivo '{input_file}' carregado. {len(df)} registros encontrados.")
    except pd.errors.EmptyDataError:
        logging.warning(f"‚ö†Ô∏è Arquivo de entrada est√° vazio ou corrompido: {input_file}")
        return
    except Exception as e:
        logging.error(f"‚ùå Erro inesperado ao ler o arquivo '{input_file}': {e}")
        raise

    colunas_necessarias = ['repo_name', 'clone_url', 'CBO', 'DIT', 'LCOM', 'LOC', 'Comments', 'Maturity']
    if not all(col in df.columns for col in colunas_necessarias):
        logging.warning(f"‚ö†Ô∏è Faltam colunas obrigat√≥rias: {colunas_necessarias}")
        return

    metricas = ['CBO', 'DIT', 'LCOM', 'LOC', 'Comments', 'Maturity']
    logging.info("üßπ Limpando e preparando os dados...")

    for col in ['CBO', 'DIT', 'LCOM']:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    for col in ['LOC', 'Comments', 'Maturity']:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    df_metricas = df[metricas].dropna()
    registros_validos = len(df_metricas)
    logging.info(f"üìà Registros v√°lidos ap√≥s limpeza: {registros_validos} de {len(df)} totais.")

    if df_metricas.empty:
        logging.warning("‚ö†Ô∏è Nenhum dado v√°lido dispon√≠vel ap√≥s limpeza. An√°lise cancelada.")
        return

    logging.info("üìâ Calculando estat√≠sticas descritivas...")
    stats = df_metricas.describe()
    logging.info("‚úÖ Estat√≠sticas calculadas com sucesso:\n" + stats.to_string())

    logging.info("üîó Calculando matriz de correla√ß√£o...")
    correlacoes = df_metricas.corr()
    logging.info("‚úÖ Matriz de correla√ß√£o calculada:\n" + correlacoes.to_string())

    try:
        stats.to_csv(output_file)
        logging.info(f"üíæ Resultados estat√≠sticos salvos no arquivo: {output_file}")
    except Exception as e:
        logging.error(f"‚ùå Erro ao salvar resultados no arquivo '{output_file}': {e}")
        raise

def main():
    logging.info("===== üöÄ INICIANDO PROCESSO DE AN√ÅLISE =====")
    try:
        input_file = verificar_arquivo_entrada()
        if input_file:
            analisar_dados(input_file)
        else:
            logging.info("‚ÑπÔ∏è Nenhum dado para analisar. Processo encerrado.")
        logging.info("üéâ Processo de an√°lise finalizado com sucesso!")
    except Exception as e:
        logging.error(f"‚ùå Processo encerrado com erro: {e}")
        raise

if __name__ == "__main__":
    main()