import os
import sys
import time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from utils import calculate_correlation, interpret_correlation, check_correlation_significance, converter_csv_json
import base64
from io import BytesIO
import shutil

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "..")))
from config_token import configurar_token

TOKEN = configurar_token()

BASE_DIR = os.path.join("Lab3_CodeRevGithub", "Lab3S03")
DATA_DIR = os.path.join(BASE_DIR, "data")

def format_seconds(seconds):
    return time.strftime('%H:%M:%S', time.gmtime(seconds))

def mover_pycache(destino="Lab3_CodeRevGithub/Lab3S03/__pycache__"):
    for root, dirs, files in os.walk("."):
        if "__pycache__" in dirs:
            origem = os.path.join(root, "__pycache__")
            if os.path.abspath(origem) == os.path.abspath(destino):
                continue  # already in the right place
            os.makedirs(destino, exist_ok=True)
            for arquivo in os.listdir(origem):
                arquivo_destino = os.path.join(destino, arquivo)
                if os.path.exists(arquivo_destino):
                    os.remove(arquivo_destino)
                shutil.move(os.path.join(origem, arquivo), destino)
            shutil.rmtree(origem)
            print(f"üì¶ Pycache movido para: {destino}")

    sns.set(style="whitegrid")
    plt.rcParams['figure.figsize'] = (10, 6)
    plt.rcParams['font.size'] = 12

def load_data(file_path):
    """
    Carrega os dados dos PRs a partir de um arquivo CSV.
    
    Args:
        file_path (str): Caminho para o arquivo CSV com os dados dos PRs
    
    Returns:
        pd.DataFrame: DataFrame com os dados dos PRs
    """
    df = pd.read_csv(file_path, sep=';')

    # Calcula o tamanho da descri√ß√£o (em n√∫mero de caracteres)
    df["body_length"] = df["body"].fillna("").apply(len)

    # Limpa e prepara os dados
    df.dropna(subset=["closed_at"], inplace=True)

    # Adiciona coluna com status final (MERGED ou CLOSED)
    df["status"] = df["merged"].apply(lambda x: "MERGED" if x else "CLOSED")

    # Converte datas para datetime
    for col in ["created_at", "closed_at", "merged_at"]:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col])
    
    return df


def save_figure_to_file(fig, filename, dpi=300):
    """
    Salva uma figura em um arquivo.
    
    Args:
        fig (matplotlib.figure.Figure): Figura a ser salva
        filename (str): Nome do arquivo
        dpi (int): Resolu√ß√£o da imagem
    """
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    fig.savefig(filename, dpi=dpi, bbox_inches='tight')
    print(f"üìÅ Figura salva em {os.path.relpath(filename)}")
    plt.close(fig)

def figure_to_base64(fig):
    """
    Converte uma figura matplotlib para base64 para inclus√£o em markdown.
    
    Args:
        fig (matplotlib.figure.Figure): Figura a ser convertida
    
    Returns:
        str: String base64 da imagem
    """
    buffer = BytesIO()
    fig.savefig(buffer, format='png', dpi=300, bbox_inches='tight')
    buffer.seek(0)
    image_png = buffer.getvalue()
    buffer.close()
    return base64.b64encode(image_png).decode('utf-8')


def create_correlation_heatmap(df, features, target, title):
    """
    Cria um mapa de calor de correla√ß√£o entre v√°rias caracter√≠sticas e um alvo.
    
    Args:
        df (pd.DataFrame): DataFrame com os dados
        features (list): Lista de colunas das caracter√≠sticas
        target (str): Coluna alvo
        title (str): T√≠tulo do gr√°fico
    
    Returns:
        matplotlib.figure.Figure: Figura com o mapa de calor
    """
    corr_data = []
    for feature in features:
        corr_val, p_val = calculate_correlation(df, feature, target, method='spearman')
        significance = '**' if check_correlation_significance(p_val) else ''
        corr_data.append({
            'Feature': feature,
            'Correlation': corr_val,
            'P-value': p_val,
            'Significance': significance
        })
    corr_df = pd.DataFrame(corr_data)
    
    fig, ax = plt.subplots(figsize=(12, len(features) * 0.8 + 2))
    bars = ax.barh(corr_df['Feature'], corr_df['Correlation'],
                    color=corr_df['Correlation'].apply(lambda x: 'skyblue' if x >= 0 else 'salmon'))
    
    for i, bar in enumerate(bars):
        significance = corr_df.iloc[i]['Significance']
        value = corr_df.iloc[i]['Correlation']
        p_value = corr_df.iloc[i]['P-value']
        if value >= 0:
            ax.text(max(value + 0.03, 0.03), i, f'{value:.3f}{significance}\np={p_value:.3e}', va='center')
        else:
            ax.text(min(value - 0.03, -0.03), i, f'{value:.3f}{significance}\np={p_value:.3e}', va='center', ha='right')
    
    ax.axvline(x=0, color='black', linestyle='-', alpha=0.3)
    ax.set_xlim(-1, 1)
    ax.set_xlabel('Coeficiente de correla√ß√£o de Spearman')
    ax.set_title(title)
    fig.text(0.9, 0.1, '** p < 0.05', fontsize=10)
    plt.tight_layout()
    return fig


def create_boxplot(df, x_col, y_col, title, xlabel, ylabel):
    """
    Cria um boxplot para comparar a distribui√ß√£o de uma vari√°vel entre dois grupos.
    
    Args:
        df (pd.DataFrame): DataFrame com os dados
        x_col (str): Coluna para o eixo x (categorias)
        y_col (str): Coluna para o eixo y (valores)
        title (str): T√≠tulo do gr√°fico
        xlabel (str): R√≥tulo do eixo x
        ylabel (str): R√≥tulo do eixo y
    
    Returns:
        matplotlib.figure.Figure: Figura com o boxplot
    """
    fig, ax = plt.subplots()
    sns.boxplot(x=x_col, y=y_col, data=df, ax=ax, palette="Set2", hue=x_col, legend=False)
    sns.stripplot(x=x_col, y=y_col, data=df, ax=ax, size=4, alpha=0.3, jitter=True, color='black')
    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    
    grouped = df.groupby(x_col)[y_col]
    medians = grouped.median()
    for i, (key, median) in enumerate(medians.items()):
        ax.text(i, median * 1.1, f'Mediana: {median:.2f}', ha='center')
    
    groups = [df[df[x_col] == category][y_col].dropna() for category in df[x_col].unique()]
    if len(groups) == 2 and len(groups[0]) > 0 and len(groups[1]) > 0:
        stat, pval = stats.mannwhitneyu(groups[0], groups[1])
        ax.text(0.5, 0.01, f'Teste Mann-Whitney: p={pval:.3e}',
                ha='center', va='bottom', transform=ax.transAxes, fontsize=10,
                bbox=dict(facecolor='white', alpha=0.8))
    plt.tight_layout()
    return fig


def create_scatter_plot(df, x_col, y_col, title, xlabel, ylabel, hue=None, log_scale=False):
    """
    Cria um gr√°fico de dispers√£o entre duas vari√°veis.
    
    Args:
        df (pd.DataFrame): DataFrame com os dados
        x_col (str): Coluna para o eixo x
        y_col (str): Coluna para o eixo y
        title (str): T√≠tulo do gr√°fico
        xlabel (str): R√≥tulo do eixo x
        ylabel (str): R√≥tulo do eixo y
        hue (str, optional): Coluna para colorir os pontos
        log_scale (bool, optional): Se True, aplicar escala logar√≠tmica aos eixos
    
    Returns:
        matplotlib.figure.Figure: Figura com o gr√°fico de dispers√£o
    """
    fig, ax = plt.subplots()
    x_data = df[x_col].copy()
    y_data = df[y_col].copy()
    if x_data.dtype in [np.float64, np.int64] and y_data.dtype in [np.float64, np.int64]:
        x_quantile = np.nanquantile(x_data, 0.99)
        y_quantile = np.nanquantile(y_data, 0.99)
        filtered_df = df[(df[x_col] <= x_quantile) & (df[y_col] <= y_quantile)].copy()
    else:
        filtered_df = df.copy()
    
    if hue:
        sns.scatterplot(x=x_col, y=y_col, data=filtered_df, hue=hue, alpha=0.6, ax=ax)
        plt.legend(title=hue, loc='upper right')
    else:
        sns.scatterplot(x=x_col, y=y_col, data=filtered_df, alpha=0.6, ax=ax)
    
    if log_scale:
        if all(filtered_df[x_col] > 0):
            ax.set_xscale('log')
        if all(filtered_df[y_col] > 0):
            ax.set_yscale('log')
    
    if filtered_df[x_col].dtype in [np.float64, np.int64] and filtered_df[y_col].dtype in [np.float64, np.int64]:
        try:
            x = filtered_df[x_col].values.reshape(-1, 1)
            y = filtered_df[y_col].values
            mask = ~(np.isnan(x.flatten()) | np.isnan(y))
            x = x[mask]
            y = y[mask]
            if len(x) > 1:
                try:
                    from sklearn.linear_model import LinearRegression
                    model = LinearRegression()
                    model.fit(x, y)
                    x_range = np.linspace(min(x), max(x), 100).reshape(-1, 1)
                    y_pred = model.predict(x_range)
                    ax.plot(x_range, y_pred, color='red', linestyle='--')
                    corr_val, p_val = calculate_correlation(filtered_df, x_col, y_col, method='spearman')
                    ax.text(0.05, 0.95, f'Corr. Spearman: {corr_val:.3f}\\np-valor: {p_val:.3e}',
                            transform=ax.transAxes, fontsize=10, va='top',
                            bbox=dict(facecolor='white', alpha=0.8))
                except ImportError:
                    print("Aviso: scikit-learn n√£o instalado; linha de tend√™ncia n√£o adicionada.")
        except Exception as e:
            print(f"Erro ao adicionar linha de tend√™ncia: {e}")
    
    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    plt.tight_layout()
    return fig


def analyze_size_vs_status(df):
    results = {}
    file_status_corr, file_status_pval = calculate_correlation(df, "files_changed", "merged", method='spearman')
    adds_status_corr, adds_status_pval = calculate_correlation(df, "additions", "merged", method='spearman')
    dels_status_corr, dels_status_pval = calculate_correlation(df, "deletions", "merged", method='spearman')
    
    results["files_vs_status"] = {
        "correlation": file_status_corr,
        "p_value": file_status_pval,
        "interpretation": interpret_correlation(file_status_corr),
        "significant": check_correlation_significance(file_status_pval)
    }
    results["additions_vs_status"] = {
        "correlation": adds_status_corr,
        "p_value": adds_status_pval,
        "interpretation": interpret_correlation(adds_status_corr),
        "significant": check_correlation_significance(adds_status_pval)
    }
    results["deletions_vs_status"] = {
        "correlation": dels_status_corr,
        "p_value": dels_status_pval,
        "interpretation": interpret_correlation(dels_status_corr),
        "significant": check_correlation_significance(dels_status_pval)
    }
    
    median_stats = df.groupby("status")[["time_to_close_hours"]].median()
    median_stats["formatted"] = median_stats["time_to_close_hours"].apply(lambda h: format_seconds(h * 3600))
    results["median_stats"] = median_stats

    
    corr_fig = create_correlation_heatmap(df, ["files_changed", "additions", "deletions"], "merged",
                                        "Correla√ß√£o entre Tamanho dos PRs e Status")
    results["correlation_plot"] = figure_to_base64(corr_fig)
    save_figure_to_file(corr_fig, os.path.join(DATA_DIR, "visualizations", "rq01_correlation.png"))

    
    for col, label in [("files_changed", "N√∫mero de Arquivos"),
                        ("additions", "Linhas Adicionadas"),
                        ("deletions", "Linhas Removidas")]:
        fig = create_boxplot(df, "status", col,
                            f"Distribui√ß√£o de {label} por Status",
                            "Status do PR", label)
        results[f"{col}_boxplot"] = figure_to_base64(fig)
        save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", f"rq01_{col}_boxplot.png"))
    
    return results


def analyze_time_vs_status(df):
    results = {}
    time_status_corr, time_status_pval = calculate_correlation(df, "time_to_close_hours", "merged", method='spearman')
    results["time_vs_status"] = {
        "correlation": time_status_corr,
        "p_value": time_status_pval,
        "interpretation": interpret_correlation(time_status_corr),
        "significant": check_correlation_significance(time_status_pval)
    }
    median_stats = df.groupby("status")[["time_to_close_hours"]].median()
    results["median_stats"] = median_stats
    
    fig = create_boxplot(df, "status", "time_to_close_hours",
                        "Distribui√ß√£o do Tempo de An√°lise por Status",
                        "Status do PR", "Tempo de An√°lise (horas)")
    results["time_boxplot"] = figure_to_base64(fig)
    save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", "rq02_time_boxplot.png"))
    
    fig, ax = plt.subplots()
    for status, color in zip(["MERGED", "CLOSED"], ["green", "red"]):
        subset = df[df["status"] == status]["time_to_close_hours"].dropna()
        cutoff = np.percentile(subset, 95)
        sns.histplot(subset[subset <= cutoff], ax=ax, color=color, alpha=0.5, label=status, kde=True)
    ax.set_title("Distribui√ß√£o do Tempo de An√°lise por Status")
    ax.set_xlabel("Tempo de An√°lise (horas)")
    ax.set_ylabel("Contagem")
    ax.legend()
    results["time_histogram"] = figure_to_base64(fig)
    save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", "rq02_time_histogram.png"))
    return results



def analyze_description_vs_status(df):
    results = {}
    desc_status_corr, desc_status_pval = calculate_correlation(df, "body_length", "merged", method='spearman')
    results["description_vs_status"] = {
        "correlation": desc_status_corr,
        "p_value": desc_status_pval,
        "interpretation": interpret_correlation(desc_status_corr),
        "significant": check_correlation_significance(desc_status_pval)
    }
    median_stats = df.groupby("status")[["body_length"]].median()
    results["median_stats"] = median_stats
    
    fig = create_boxplot(df, "status", "body_length",
                        "Distribui√ß√£o do Tamanho da Descri√ß√£o por Status",
                        "Status do PR", "Tamanho da Descri√ß√£o (caracteres)")
    results["description_boxplot"] = figure_to_base64(fig)
    save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", "rq03_description_boxplot.png"))

    fig, ax = plt.subplots()
    medians = df.groupby("status")["body_length"].median()
    bars = ax.bar(medians.index, medians.values, color=["green", "red"])
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2., height * 1.01,
                f'{height:.1f}', ha='center', va='bottom')
    ax.set_title("Mediana do Tamanho da Descri√ß√£o por Status")
    ax.set_xlabel("Status do PR")
    ax.set_ylabel("Tamanho Mediano da Descri√ß√£o (caracteres)")
    results["description_bars"] = figure_to_base64(fig)
    save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", "rq03_description_bars.png"))
    
    return results

def analyze_interactions_vs_status(df):
    results = {}
    part_status_corr, part_status_pval = calculate_correlation(df, "participant_count", "merged", method='spearman')
    comm_status_corr, comm_status_pval = calculate_correlation(df, "comments", "merged", method='spearman')
    rev_comm_status_corr, rev_comm_status_pval = calculate_correlation(df, "review_comments", "merged", method='spearman')
    
    results["participants_vs_status"] = {
        "correlation": part_status_corr,
        "p_value": part_status_pval,
        "interpretation": interpret_correlation(part_status_corr),
        "significant": check_correlation_significance(part_status_pval)
    }
    results["comments_vs_status"] = {
        "correlation": comm_status_corr,
        "p_value": comm_status_pval,
        "interpretation": interpret_correlation(comm_status_corr),
        "significant": check_correlation_significance(comm_status_pval)
    }
    results["review_comments_vs_status"] = {
        "correlation": rev_comm_status_corr,
        "p_value": rev_comm_status_pval,
        "interpretation": interpret_correlation(rev_comm_status_corr),
        "significant": check_correlation_significance(rev_comm_status_pval)
    }
    median_stats = df.groupby("status")[["participant_count", "comments", "review_comments"]].median()
    results["median_stats"] = median_stats
    
    corr_fig = create_correlation_heatmap(df, ["participant_count", "comments", "review_comments"], "merged",
                                        "Correla√ß√£o entre Intera√ß√µes e Status")
    results["correlation_plot"] = figure_to_base64(corr_fig)
    save_figure_to_file(corr_fig, os.path.join(DATA_DIR, "visualizations", "rq04_correlation.png"))
    
    for col, label in [("participant_count", "N√∫mero de Participantes"),
                        ("comments", "N√∫mero de Coment√°rios"),
                        ("review_comments", "N√∫mero de Coment√°rios de Revis√£o")]:
        fig = create_boxplot(df, "status", col,
                            f"Distribui√ß√£o de {label} por Status",
                            "Status do PR", label)
        results[f"{col}_boxplot"] = figure_to_base64(fig)
        save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", f"rq04_{col}_boxplot.png"))
    
    return results

def analyze_size_vs_reviews(df):
    results = {}
    file_rev_corr, file_rev_pval = calculate_correlation(df, "files_changed", "review_count", method='spearman')
    adds_rev_corr, adds_rev_pval = calculate_correlation(df, "additions", "review_count", method='spearman')
    dels_rev_corr, dels_rev_pval = calculate_correlation(df, "deletions", "review_count", method='spearman')
    
    results["files_vs_reviews"] = {
        "correlation": file_rev_corr,
        "p_value": file_rev_pval,
        "interpretation": interpret_correlation(file_rev_corr),
        "significant": check_correlation_significance(file_rev_pval)
    }
    results["additions_vs_reviews"] = {
        "correlation": adds_rev_corr,
        "p_value": adds_rev_pval,
        "interpretation": interpret_correlation(adds_rev_corr),
        "significant": check_correlation_significance(adds_rev_pval)
    }
    results["deletions_vs_reviews"] = {
        "correlation": dels_rev_corr,
        "p_value": dels_rev_pval,
        "interpretation": interpret_correlation(dels_rev_corr),
        "significant": check_correlation_significance(dels_rev_pval)
    }
    
    corr_fig = create_correlation_heatmap(df, ["files_changed", "additions", "deletions"], "review_count",
                                        "Correla√ß√£o entre Tamanho dos PRs e N√∫mero de Revis√µes")
    results["correlation_plot"] = figure_to_base64(corr_fig)
    save_figure_to_file(corr_fig, os.path.join(DATA_DIR, "visualizations", "rq05_correlation.png"))
    
    for col, label in [("files_changed", "N√∫mero de Arquivos"),
                        ("additions", "Linhas Adicionadas"),
                        ("deletions", "Linhas Removidas")]:
        fig = create_scatter_plot(df, col, "review_count",
                                f"Rela√ß√£o entre {label} e N√∫mero de Revis√µes",
                                label, "N√∫mero de Revis√µes", log_scale=True)
        results[f"{col}_scatter"] = figure_to_base64(fig)
        save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", f"rq05_{col}_scatter.png"))
    
    return results


def analyze_time_vs_reviews(df):
    results = {}
    time_rev_corr, time_rev_pval = calculate_correlation(df, "time_to_close_hours", "review_count", method='spearman')
    results["time_vs_reviews"] = {
        "correlation": time_rev_corr,
        "p_value": time_rev_pval,
        "interpretation": interpret_correlation(time_rev_corr),
        "significant": check_correlation_significance(time_rev_pval)
    }
    
    fig = create_scatter_plot(df, "time_to_close_hours", "review_count",
                                "Rela√ß√£o entre Tempo de An√°lise e N√∫mero de Revis√µes",
                                "Tempo de An√°lise (horas)", "N√∫mero de Revis√µes", log_scale=True)
    results["time_scatter"] = figure_to_base64(fig)
    save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", "rq06_time_scatter.png"))
    
    fig, ax = plt.subplots()
    df['time_bins'] = pd.cut(df['time_to_close_hours'],
                            bins=[0, 24, 48, 72, 168, df['time_to_close_hours'].max()],
                            labels=['0-24h', '24-48h', '48-72h', '72h-1 semana', '> 1 semana'])
    time_bin_means = df.groupby('time_bins', observed=False)['review_count'].mean().reset_index()
    time_bin_counts = df.groupby('time_bins', observed=False).size().reset_index(name='count')
    time_bin_data = pd.merge(time_bin_means, time_bin_counts, on='time_bins')
    ax.plot(time_bin_data['time_bins'], time_bin_data['review_count'], marker='o', linestyle='-')
    for i, row in time_bin_data.iterrows():
        ax.annotate(f"n={row['count']}", (i, row['review_count']),
                    textcoords="offset points", xytext=(0, 10), ha='center')
    ax.set_title("M√©dia de Revis√µes por Faixa de Tempo")
    ax.set_xlabel("Tempo de An√°lise")
    ax.set_ylabel("M√©dia de Revis√µes")
    plt.xticks(rotation=45)
    plt.tight_layout()
    results["time_bins_plot"] = figure_to_base64(fig)
    save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", "rq06_time_bins.png"))
    
    return results


def analyze_description_vs_reviews(df):
    results = {}
    desc_rev_corr, desc_rev_pval = calculate_correlation(df, "body_length", "review_count", method='spearman')
    results["description_vs_reviews"] = {
        "correlation": desc_rev_corr,
        "p_value": desc_rev_pval,
        "interpretation": interpret_correlation(desc_rev_corr),
        "significant": check_correlation_significance(desc_rev_pval)
    }
    
    fig = create_scatter_plot(df, "body_length", "review_count",
                            "Rela√ß√£o entre Tamanho da Descri√ß√£o e N√∫mero de Revis√µes",
                            "Tamanho da Descri√ß√£o (caracteres)", "N√∫mero de Revis√µes", log_scale=True)
    results["description_scatter"] = figure_to_base64(fig)
    save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", "rq07_description_scatter.png"))
    
    fig, ax = plt.subplots()
    last_bin = max(2001, df['body_length'].max())
    df['desc_bins'] = pd.cut(df['body_length'],
                            bins=[0, 100, 500, 1000, 2000, last_bin],
                            labels=['0-100', '100-500', '500-1000', '1000-2000', '> 2000'])
    desc_bin_means = df.groupby('desc_bins', observed=False)['review_count'].mean().reset_index()
    desc_bin_counts = df.groupby('desc_bins', observed=False).size().reset_index(name='count')
    desc_bin_data = pd.merge(desc_bin_means, desc_bin_counts, on='desc_bins')
    bars = ax.bar(desc_bin_data['desc_bins'], desc_bin_data['review_count'])
    for i, bar in enumerate(bars):
        height = bar.get_height()
        count = desc_bin_data.iloc[i]['count']
        ax.text(bar.get_x() + bar.get_width() / 2., height + 0.1, f"n={count}", ha='center', va='bottom')
    ax.set_title("M√©dia de Revis√µes por Tamanho de Descri√ß√£o")
    ax.set_xlabel("Tamanho da Descri√ß√£o (caracteres)")
    ax.set_ylabel("M√©dia de Revis√µes")
    plt.xticks(rotation=45)
    plt.tight_layout()
    results["desc_bins_plot"] = figure_to_base64(fig)
    save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", "rq07_desc_bins.png"))
    
    return results


def analyze_interactions_vs_reviews(df):
    results = {}
    part_rev_corr, part_rev_pval = calculate_correlation(df, "participant_count", "review_count", method='spearman')
    comm_rev_corr, comm_rev_pval = calculate_correlation(df, "comments", "review_count", method='spearman')
    rev_comm_rev_corr, rev_comm_rev_pval = calculate_correlation(df, "review_comments", "review_count", method='spearman')
    
    results["participants_vs_reviews"] = {
        "correlation": part_rev_corr,
        "p_value": part_rev_pval,
        "interpretation": interpret_correlation(part_rev_corr),
        "significant": check_correlation_significance(part_rev_pval)
    }
    results["comments_vs_reviews"] = {
        "correlation": comm_rev_corr,
        "p_value": comm_rev_pval,
        "interpretation": interpret_correlation(comm_rev_corr),
        "significant": check_correlation_significance(comm_rev_pval)
    }
    results["review_comments_vs_reviews"] = {
        "correlation": rev_comm_rev_corr,
        "p_value": rev_comm_rev_pval,
        "interpretation": interpret_correlation(rev_comm_rev_corr),
        "significant": check_correlation_significance(rev_comm_rev_pval)
    }
    
    corr_fig = create_correlation_heatmap(df, ["participant_count", "comments", "review_comments"],
                                        "review_count", "Correla√ß√£o entre Intera√ß√µes e N√∫mero de Revis√µes")
    results["correlation_plot"] = figure_to_base64(corr_fig)
    save_figure_to_file(corr_fig, os.path.join(DATA_DIR, "visualizations", "rq08_correlation.png"))
    
    for col, label in [("participant_count", "N√∫mero de Participantes"),
                        ("comments", "N√∫mero de Coment√°rios"),
                        ("review_comments", "N√∫mero de Coment√°rios de Revis√£o")]:
        fig = create_scatter_plot(df, col, "review_count",
                                f"Rela√ß√£o entre {label} e N√∫mero de Revis√µes",
                                label, "N√∫mero de Revis√µes")
        results[f"{col}_scatter"] = figure_to_base64(fig)
        save_figure_to_file(fig, os.path.join(DATA_DIR, "visualizations", f"rq08_{col}_scatter.png"))

    
    return results


def generate_report(df, all_results, output_file="report.md"):
    os.makedirs("data/visualizations", exist_ok=True)
    report = []
    report.append("# Relat√≥rio de An√°lise da Atividade de Code Review no GitHub")
    report.append("\n## Introdu√ß√£o")
    report.append("\nEste relat√≥rio apresenta os resultados da an√°lise da atividade de code review em reposit√≥rios populares do GitHub. O objetivo √© identificar vari√°veis que influenciam no merge de um PR, sob a perspectiva de desenvolvedores que submetem c√≥digo aos reposit√≥rios selecionados.")
    report.append("\n### Hip√≥teses Informais")
    report.append("\n1. PRs menores t√™m maior probabilidade de serem aprovados.")
    report.append("2. PRs que levam mais tempo para serem analisados t√™m menor probabilidade de serem aprovados.")
    report.append("3. PRs com descri√ß√µes mais detalhadas t√™m maior probabilidade de serem aprovados.")
    report.append("4. PRs com mais intera√ß√µes t√™m maior probabilidade de serem aprovados.")
    report.append("5. PRs maiores requerem mais revis√µes.")
    report.append("6. PRs que levam mais tempo para serem analisados t√™m mais revis√µes.")
    report.append("7. PRs com descri√ß√µes mais detalhadas t√™m menos revis√µes.")
    report.append("8. PRs com mais intera√ß√µes t√™m mais revis√µes.")
    report.append("\n## Metodologia")
    report.append("\nPara realizar esta an√°lise, seguimos os seguintes passos:")
    report.append("\n1. **Coleta de dados**: Selecionamos os 200 reposit√≥rios mais populares do GitHub com pelo menos 100 PRs (MERGED + CLOSED).")
    report.append("\n2. **Filtragem dos dados**: Selecionamos apenas PRs com status MERGED ou CLOSED, que possu√≠am pelo menos uma revis√£o e cuja an√°lise levou pelo menos uma hora.")
    report.append("\n3. **An√°lise estat√≠stica**: Utilizamos o coeficiente de correla√ß√£o de Spearman para analisar as rela√ß√µes entre as vari√°veis, pois esse m√©todo n√£o assume que os dados seguem uma distribui√ß√£o normal e √© menos sens√≠vel a outliers. O coeficiente de Spearman √© adequado para dados que n√£o necessariamente t√™m uma rela√ß√£o linear, medindo a for√ßa e dire√ß√£o de uma associa√ß√£o monot√¥nica entre duas vari√°veis.")
    report.append("\n4. **Interpreta√ß√£o dos resultados**: Interpretamos os coeficientes de correla√ß√£o da seguinte forma:")
    report.append("   - |r| < 0.1: Correla√ß√£o insignificante")
    report.append("   - 0.1 ‚â§ |r| < 0.3: Correla√ß√£o fraca")
    report.append("   - 0.3 ‚â§ |r| < 0.5: Correla√ß√£o moderada")
    report.append("   - 0.5 ‚â§ |r| < 0.7: Correla√ß√£o forte")
    report.append("   - |r| ‚â• 0.7: Correla√ß√£o muito forte")
    report.append("\n   Consideramos correla√ß√µes estatisticamente significativas aquelas com p-valor < 0.05.")
    report.append("\n## Resultados")
    
    # RQ 01
    report.append("\n### RQ 01: Rela√ß√£o entre o tamanho dos PRs e o feedback final das revis√µes")
    if "size_vs_status" in all_results:
        results = all_results["size_vs_status"]
        report.append("\n**Correla√ß√£o entre m√©tricas de tamanho e status:**")
        report.append(f"\n![Correla√ß√£o entre Tamanho dos PRs e Status](data/visualizations/rq01_correlation.png)")
        report.append("\n**Correla√ß√£o entre n√∫mero de arquivos alterados e status:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['files_vs_status']['correlation']:.4f}")
        report.append(f"- P-valor: {results['files_vs_status']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['files_vs_status']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['files_vs_status']['significant'] else 'N√£o'}")
        report.append(f"\n![Distribui√ß√£o de Arquivos por Status](data/visualizations/rq01_files_changed_boxplot.png)")
        report.append("\n**Correla√ß√£o entre linhas adicionadas e status:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['additions_vs_status']['correlation']:.4f}")
        report.append(f"- P-valor: {results['additions_vs_status']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['additions_vs_status']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['additions_vs_status']['significant'] else 'N√£o'}")
        report.append(f"\n![Distribui√ß√£o de Linhas Adicionadas por Status](data/visualizations/rq01_additions_boxplot.png)")
        report.append("\n**Correla√ß√£o entre linhas removidas e status:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['deletions_vs_status']['correlation']:.4f}")
        report.append(f"- P-valor: {results['deletions_vs_status']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['deletions_vs_status']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['deletions_vs_status']['significant'] else 'N√£o'}")
        report.append(f"\n![Distribui√ß√£o de Linhas Removidas por Status](data/visualizations/rq01_deletions_boxplot.png)")
        report.append("\n**Estat√≠sticas descritivas (medianas):**")

        # Calcular as medianas por status
        median_stats_mediana = df.groupby("status")[['files_changed', 'additions', 'deletions']].median()
        median_stats_media = df.groupby("status")[['files_changed', 'additions', 'deletions']].mean()

        # Adicionar as informa√ß√µes ao relat√≥rio - Mediana
        report.append(f"- PRs mesclados (MERGED):")
        report.append(f"  - Arquivos alterados: {median_stats_mediana.loc['MERGED', 'files_changed']:.2f}")
        report.append(f"  - Linhas adicionadas: {median_stats_mediana.loc['MERGED', 'additions']:.2f}")
        report.append(f"  - Linhas removidas: {median_stats_mediana.loc['MERGED', 'deletions']:.2f}")
        report.append(f"- PRs fechados sem merge (CLOSED):")
        report.append(f"  - Arquivos alterados: {median_stats_mediana.loc['CLOSED', 'files_changed']:.2f}")
        report.append(f"  - Linhas adicionadas: {median_stats_mediana.loc['CLOSED', 'additions']:.2f}")
        report.append(f"  - Linhas removidas: {median_stats_mediana.loc['CLOSED', 'deletions']:.2f}")

        report.append("\n**Estat√≠sticas descritivas (m√©dia):**")

        # Adicionar as informa√ß√µes ao relat√≥rio - M√©dia
        report.append(f"- PRs mesclados (MERGED):")
        report.append(f"  - Arquivos alterados: {median_stats_media.loc['MERGED', 'files_changed']:.2f}")
        report.append(f"  - Linhas adicionadas: {median_stats_media.loc['MERGED', 'additions']:.2f}")
        report.append(f"  - Linhas removidas: {median_stats_mediana.loc['MERGED', 'deletions']:.2f}")
        report.append(f"- PRs fechados sem merge (CLOSED):")
        report.append(f"  - Arquivos alterados: {median_stats_media.loc['CLOSED', 'files_changed']:.2f}")
        report.append(f"  - Linhas adicionadas: {median_stats_media.loc['CLOSED', 'additions']:.2f}")
        report.append(f"  - Linhas removidas: {median_stats_media.loc['CLOSED', 'deletions']:.2f}")
    
    # RQ 02
    report.append("\n### RQ 02: Rela√ß√£o entre o tempo de an√°lise dos PRs e o feedback final das revis√µes")
    if "time_vs_status" in all_results:
        results = all_results["time_vs_status"]
        report.append("\n**Correla√ß√£o entre tempo de an√°lise e status:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['time_vs_status']['correlation']:.4f}")
        report.append(f"- P-valor: {results['time_vs_status']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['time_vs_status']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['time_vs_status']['significant'] else 'N√£o'}")
        report.append(f"\n![Distribui√ß√£o do Tempo de An√°lise por Status](data/visualizations/rq02_time_boxplot.png)")
        report.append(f"\n![Histograma do Tempo de An√°lise por Status](data/visualizations/rq02_time_histogram.png)")
        report.append("\n**Estat√≠sticas descritivas (medianas):**")
        report.append(f"- PRs mesclados (MERGED): {results['median_stats'].loc['MERGED', 'time_to_close_hours']:.2f} horas")
        report.append(f"- PRs fechados sem merge (CLOSED): {results['median_stats'].loc['CLOSED', 'time_to_close_hours']:.2f} horas")
    
    # RQ 03
    report.append("\n### RQ 03: Rela√ß√£o entre a descri√ß√£o dos PRs e o feedback final das revis√µes")
    if "description_vs_status" in all_results:
        results = all_results["description_vs_status"]
        report.append("\n**Correla√ß√£o entre tamanho da descri√ß√£o e status:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['description_vs_status']['correlation']:.4f}")
        report.append(f"- P-valor: {results['description_vs_status']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['description_vs_status']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['description_vs_status']['significant'] else 'N√£o'}")
        report.append(f"\n![Distribui√ß√£o do Tamanho da Descri√ß√£o por Status](data/visualizations/rq03_description_boxplot.png)")
        report.append(f"\n![Mediana do Tamanho da Descri√ß√£o por Status](data/visualizations/rq03_description_bars.png)")
        report.append("\n**Estat√≠sticas descritivas (medianas):**")
        report.append(f"- PRs mesclados (MERGED): {results['median_stats'].loc['MERGED', 'body_length']:.2f} caracteres")
        report.append(f"- PRs fechados sem merge (CLOSED): {results['median_stats'].loc['CLOSED', 'body_length']:.2f} caracteres")
    
    # RQ 04
    report.append("\n### RQ 04: Rela√ß√£o entre as intera√ß√µes nos PRs e o feedback final das revis√µes")
    if "interactions_vs_status" in all_results:
        results = all_results["interactions_vs_status"]
        report.append("\n**Correla√ß√£o entre m√©tricas de intera√ß√£o e status:**")
        report.append(f"\n![Correla√ß√£o entre Intera√ß√µes e Status](data/visualizations/rq04_correlation.png)")
        report.append("\n**Correla√ß√£o entre n√∫mero de participantes e status:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['participants_vs_status']['correlation']:.4f}")
        report.append(f"- P-valor: {results['participants_vs_status']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['participants_vs_status']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['participants_vs_status']['significant'] else 'N√£o'}")
        report.append(f"\n![Distribui√ß√£o de Participantes por Status](data/visualizations/rq04_participant_count_boxplot.png)")
        report.append("\n**Correla√ß√£o entre n√∫mero de coment√°rios e status:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['comments_vs_status']['correlation']:.4f}")
        report.append(f"- P-valor: {results['comments_vs_status']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['comments_vs_status']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['comments_vs_status']['significant'] else 'N√£o'}")
        report.append(f"\n![Distribui√ß√£o de Coment√°rios por Status](data/visualizations/rq04_comments_boxplot.png)")
        report.append("\n**Correla√ß√£o entre n√∫mero de coment√°rios de revis√£o e status:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['review_comments_vs_status']['correlation']:.4f}")
        report.append(f"- P-valor: {results['review_comments_vs_status']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['review_comments_vs_status']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['review_comments_vs_status']['significant'] else 'N√£o'}")
        report.append(f"\n![Distribui√ß√£o de Coment√°rios de Revis√£o por Status](data/visualizations/rq04_review_comments_boxplot.png)")
        report.append("\n**Estat√≠sticas descritivas (medianas):**")
        report.append(f"- PRs mesclados (MERGED):")
        report.append(f"  - Participantes: {results['median_stats'].loc['MERGED', 'participant_count']:.2f}")
        report.append(f"  - Coment√°rios: {results['median_stats'].loc['MERGED', 'comments']:.2f}")
        report.append(f"  - Coment√°rios de revis√£o: {results['median_stats'].loc['MERGED', 'review_comments']:.2f}")
        report.append(f"- PRs fechados sem merge (CLOSED):")
        report.append(f"  - Participantes: {results['median_stats'].loc['CLOSED', 'participant_count']:.2f}")
        report.append(f"  - Coment√°rios: {results['median_stats'].loc['CLOSED', 'comments']:.2f}")
        report.append(f"  - Coment√°rios de revis√£o: {results['median_stats'].loc['CLOSED', 'review_comments']:.2f}")
    
    # RQ 05
    report.append("\n### RQ 05: Rela√ß√£o entre o tamanho dos PRs e o n√∫mero de revis√µes realizadas")
    if "size_vs_reviews" in all_results:
        results = all_results["size_vs_reviews"]
        report.append("\n**Correla√ß√£o entre m√©tricas de tamanho e n√∫mero de revis√µes:**")
        report.append(f"\n![Correla√ß√£o entre Tamanho dos PRs e N√∫mero de Revis√µes](data/visualizations/rq05_correlation.png)")
        report.append("\n**Correla√ß√£o entre n√∫mero de arquivos alterados e n√∫mero de revis√µes:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['files_vs_reviews']['correlation']:.4f}")
        report.append(f"- P-valor: {results['files_vs_reviews']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['files_vs_reviews']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['files_vs_reviews']['significant'] else 'N√£o'}")
        report.append(f"\n![Rela√ß√£o entre N√∫mero de Arquivos e Revis√µes](data/visualizations/rq05_files_changed_scatter.png)")
        report.append("\n**Correla√ß√£o entre linhas adicionadas e n√∫mero de revis√µes:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['additions_vs_reviews']['correlation']:.4f}")
        report.append(f"- P-valor: {results['additions_vs_reviews']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['additions_vs_reviews']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['additions_vs_reviews']['significant'] else 'N√£o'}")
        report.append(f"\n![Rela√ß√£o entre Linhas Adicionadas e Revis√µes](data/visualizations/rq05_additions_scatter.png)")
        report.append("\n**Correla√ß√£o entre linhas removidas e n√∫mero de revis√µes:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['deletions_vs_reviews']['correlation']:.4f}")
        report.append(f"- P-valor: {results['deletions_vs_reviews']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['deletions_vs_reviews']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['deletions_vs_reviews']['significant'] else 'N√£o'}")
        report.append(f"\n![Rela√ß√£o entre Linhas Removidas e Revis√µes](data/visualizations/rq05_deletions_scatter.png)")
    
    # RQ 06
    report.append("\n### RQ 06: Rela√ß√£o entre o tempo de an√°lise dos PRs e o n√∫mero de revis√µes realizadas")
    if "time_vs_reviews" in all_results:
        results = all_results["time_vs_reviews"]
        report.append("\n**Correla√ß√£o entre tempo de an√°lise e n√∫mero de revis√µes:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['time_vs_reviews']['correlation']:.4f}")
        report.append(f"- P-valor: {results['time_vs_reviews']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['time_vs_reviews']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['time_vs_reviews']['significant'] else 'N√£o'}")
        report.append(f"\n![Rela√ß√£o entre Tempo de An√°lise e Revis√µes](data/visualizations/rq06_time_scatter.png)")
        report.append(f"\n![M√©dia de Revis√µes por Faixa de Tempo](data/visualizations/rq06_time_bins.png)")
    
    # RQ 07
    report.append("\n### RQ 07: Rela√ß√£o entre a descri√ß√£o dos PRs e o n√∫mero de revis√µes realizadas")
    if "description_vs_reviews" in all_results:
        results = all_results["description_vs_reviews"]
        report.append("\n**Correla√ß√£o entre tamanho da descri√ß√£o e n√∫mero de revis√µes:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['description_vs_reviews']['correlation']:.4f}")
        report.append(f"- P-valor: {results['description_vs_reviews']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['description_vs_reviews']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['description_vs_reviews']['significant'] else 'N√£o'}")
        report.append(f"\n![Rela√ß√£o entre Tamanho da Descri√ß√£o e Revis√µes](data/visualizations/rq07_description_scatter.png)")
        report.append(f"\n![M√©dia de Revis√µes por Tamanho de Descri√ß√£o](data/visualizations/rq07_desc_bins.png)")
    
    # RQ 08
    report.append("\n### RQ 08: Rela√ß√£o entre as intera√ß√µes nos PRs e o n√∫mero de revis√µes realizadas")
    if "interactions_vs_reviews" in all_results:
        results = all_results["interactions_vs_reviews"]
        report.append("\n**Correla√ß√£o entre m√©tricas de intera√ß√£o e n√∫mero de revis√µes:**")
        report.append(f"\n![Correla√ß√£o entre Intera√ß√µes e N√∫mero de Revis√µes](data/visualizations/rq08_correlation.png)")
        report.append("\n**Correla√ß√£o entre n√∫mero de participantes e n√∫mero de revis√µes:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['participants_vs_reviews']['correlation']:.4f}")
        report.append(f"- P-valor: {results['participants_vs_reviews']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['participants_vs_reviews']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['participants_vs_reviews']['significant'] else 'N√£o'}")
        report.append(f"\n![Rela√ß√£o entre N√∫mero de Participantes e Revis√µes](data/visualizations/rq08_participant_count_scatter.png)")
        report.append("\n**Correla√ß√£o entre n√∫mero de coment√°rios e n√∫mero de revis√µes:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['comments_vs_reviews']['correlation']:.4f}")
        report.append(f"- P-valor: {results['comments_vs_reviews']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['comments_vs_reviews']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['comments_vs_reviews']['significant'] else 'N√£o'}")
        report.append(f"\n![Rela√ß√£o entre N√∫mero de Coment√°rios e Revis√µes](data/visualizations/rq08_comments_scatter.png)")
        report.append("\n**Correla√ß√£o entre n√∫mero de coment√°rios de revis√£o e n√∫mero de revis√µes:**")
        report.append(f"- Coeficiente de correla√ß√£o: {results['review_comments_vs_reviews']['correlation']:.4f}")
        report.append(f"- P-valor: {results['review_comments_vs_reviews']['p_value']:.4e}")
        report.append(f"- Interpreta√ß√£o: {results['review_comments_vs_reviews']['interpretation']}")
        report.append(f"- Estatisticamente significativo: {'Sim' if results['review_comments_vs_reviews']['significant'] else 'N√£o'}")
        report.append(f"\n![Rela√ß√£o entre N√∫mero de Coment√°rios de Revis√£o e Revis√µes](data/visualizations/rq08_review_comments_scatter.png)")
    
    # Discuss√£o e Conclus√£o
    report.append("\n## Discuss√£o")
    report.append("\nNesta se√ß√£o, discutimos os resultados obtidos em rela√ß√£o √†s nossas hip√≥teses iniciais.")
    report.append("\n### RQ 01: Rela√ß√£o entre o tamanho dos PRs e o feedback final das revis√µes")
    report.append("\nHip√≥tese: PRs menores t√™m maior probabilidade de serem aprovados.")
    if "size_vs_status" in all_results:
        results = all_results["size_vs_status"]
        if results['files_vs_status']['correlation'] < 0 and results['files_vs_status']['significant']:
            report.append("\nOs resultados suportam nossa hip√≥tese. Encontramos uma correla√ß√£o " +
                          results['files_vs_status']['interpretation'].lower() +
                          " e estatisticamente significativa entre o n√∫mero de arquivos alterados e a aprova√ß√£o do PR. " +
                          "PRs com menos arquivos alterados t√™m maior probabilidade de serem aprovados.")
        else:
            report.append("\nOs resultados n√£o suportam completamente nossa hip√≥tese. A correla√ß√£o entre o tamanho do PR e sua aprova√ß√£o n√£o foi t√£o forte ou significativa como esper√°vamos.")
    report.append("\n### RQ 02: Rela√ß√£o entre o tempo de an√°lise dos PRs e o feedback final das revis√µes")
    report.append("\nHip√≥tese: PRs que levam mais tempo para serem analisados t√™m menor probabilidade de serem aprovados.")
    if "time_vs_status" in all_results:
        results = all_results["time_vs_status"]
        if results['time_vs_status']['correlation'] < 0 and results['time_vs_status']['significant']:
            report.append("\nOs resultados suportam nossa hip√≥tese. Encontramos uma correla√ß√£o " +
                          results['time_vs_status']['interpretation'].lower() +
                          " e estatisticamente significativa entre o tempo de an√°lise e a aprova√ß√£o do PR. " +
                          "PRs que levam mais tempo para serem analisados t√™m menor probabilidade de serem aprovados.")
        else:
            report.append("\nOs resultados n√£o suportam completamente nossa hip√≥tese. A correla√ß√£o entre o tempo de an√°lise e a aprova√ß√£o do PR n√£o foi t√£o forte ou significativa como esper√°vamos.")
    report.append("\n### RQ 03: Rela√ß√£o entre a descri√ß√£o dos PRs e o feedback final das revis√µes")
    report.append("\nHip√≥tese: PRs com descri√ß√µes mais detalhadas t√™m maior probabilidade de serem aprovados.")
    if "description_vs_status" in all_results:
        results = all_results["description_vs_status"]
        if results['description_vs_status']['correlation'] > 0 and results['description_vs_status']['significant']:
            report.append("\nOs resultados suportam nossa hip√≥tese. Encontramos uma correla√ß√£o " +
                          results['description_vs_status']['interpretation'].lower() +
                          " e estatisticamente significativa entre o tamanho da descri√ß√£o e a aprova√ß√£o do PR. " +
                          "PRs com descri√ß√µes mais detalhadas t√™m maior probabilidade de serem aprovados.")
        else:
            report.append("\nOs resultados n√£o suportam completamente nossa hip√≥tese. A correla√ß√£o entre o tamanho da descri√ß√£o e a aprova√ß√£o do PR n√£o foi t√£o forte ou significativa como esper√°vamos.")
    report.append("\n### RQ 04: Rela√ß√£o entre as intera√ß√µes nos PRs e o feedback final das revis√µes")
    report.append("\nHip√≥tese: PRs com mais intera√ß√µes t√™m maior probabilidade de serem aprovados.")
    if "interactions_vs_status" in all_results:
        results = all_results["interactions_vs_status"]
        if (results['participants_vs_status']['correlation'] > 0 and results['participants_vs_status']['significant']) or \
           (results['comments_vs_status']['correlation'] > 0 and results['comments_vs_status']['significant']) or \
           (results['review_comments_vs_status']['correlation'] > 0 and results['review_comments_vs_status']['significant']):
            report.append("\nOs resultados suportam parcialmente nossa hip√≥tese. Encontramos correla√ß√µes significativas entre algumas m√©tricas de intera√ß√£o e a aprova√ß√£o do PR. " +
                          "PRs com mais intera√ß√µes tendem a ter maior probabilidade de serem aprovados, possivelmente porque problemas s√£o identificados e resolvidos durante o processo de revis√£o.")
        else:
            report.append("\nOs resultados n√£o suportam nossa hip√≥tese. As correla√ß√µes entre as m√©tricas de intera√ß√£o e a aprova√ß√£o do PR n√£o foram t√£o fortes ou significativas como esper√°vamos.")
    report.append("\n### RQ 05: Rela√ß√£o entre o tamanho dos PRs e o n√∫mero de revis√µes realizadas")
    report.append("\nHip√≥tese: PRs maiores requerem mais revis√µes.")
    if "size_vs_reviews" in all_results:
        results = all_results["size_vs_reviews"]
        if (results['files_vs_reviews']['correlation'] > 0 and results['files_vs_reviews']['significant']) or \
           (results['additions_vs_reviews']['correlation'] > 0 and results['additions_vs_reviews']['significant']) or \
           (results['deletions_vs_reviews']['correlation'] > 0 and results['deletions_vs_reviews']['significant']):
            report.append("\nOs resultados suportam nossa hip√≥tese. Encontramos correla√ß√µes significativas entre o tamanho do PR e o n√∫mero de revis√µes realizadas. " +
                          "PRs maiores tendem a requerer mais revis√µes, possivelmente porque cont√™m mais c√≥digo a ser analisado e mais problemas potenciais a serem identificados.")
        else:
            report.append("\nOs resultados n√£o suportam completamente nossa hip√≥tese. As correla√ß√µes entre o tamanho do PR e o n√∫mero de revis√µes n√£o foram t√£o fortes ou significativas como esper√°vamos.")
    report.append("\n### RQ 06: Rela√ß√£o entre o tempo de an√°lise dos PRs e o n√∫mero de revis√µes realizadas")
    report.append("\nHip√≥tese: PRs que levam mais tempo para serem analisados t√™m mais revis√µes.")
    if "time_vs_reviews" in all_results:
        results = all_results["time_vs_reviews"]
        if results['time_vs_reviews']['correlation'] > 0 and results['time_vs_reviews']['significant']:
            report.append("\nOs resultados suportam nossa hip√≥tese. Encontramos uma correla√ß√£o " +
                          results['time_vs_reviews']['interpretation'].lower() +
                          " e estatisticamente significativa entre o tempo de an√°lise e o n√∫mero de revis√µes. " +
                          "PRs que levam mais tempo para serem analisados t√™m mais revis√µes, possivelmente porque revis√µes adicionais s√£o necess√°rias para resolver problemas identificados.")
        else:
            report.append("\nOs resultados n√£o suportam completamente nossa hip√≥tese. A correla√ß√£o entre o tempo de an√°lise e o n√∫mero de revis√µes n√£o foi t√£o forte ou significativa como esper√°vamos.")
    report.append("\n### RQ 07: Rela√ß√£o entre a descri√ß√£o dos PRs e o n√∫mero de revis√µes realizadas")
    report.append("\nHip√≥tese: PRs com descri√ß√µes mais detalhadas t√™m menos revis√µes.")
    if "description_vs_reviews" in all_results:
        results = all_results["description_vs_reviews"]
        if results['description_vs_reviews']['correlation'] < 0 and results['description_vs_reviews']['significant']:
            report.append("\nOs resultados suportam nossa hip√≥tese. Encontramos uma correla√ß√£o " +
                          results['description_vs_reviews']['interpretation'].lower() +
                          " e estatisticamente significativa entre o tamanho da descri√ß√£o e o n√∫mero de revis√µes. " +
                          "PRs com descri√ß√µes mais detalhadas t√™m menos revis√µes, possivelmente porque os revisores entendem melhor o prop√≥sito e o contexto do PR.")
        else:
            report.append("\nOs resultados n√£o suportam nossa hip√≥tese. A correla√ß√£o entre o tamanho da descri√ß√£o e o n√∫mero de revis√µes n√£o foi negativa ou significativa como esper√°vamos.")
    report.append("\n### RQ 08: Rela√ß√£o entre as intera√ß√µes nos PRs e o n√∫mero de revis√µes realizadas")
    report.append("\nHip√≥tese: PRs com mais intera√ß√µes t√™m mais revis√µes.")
    if "interactions_vs_reviews" in all_results:
        results = all_results["interactions_vs_reviews"]
        if (results['participants_vs_reviews']['correlation'] > 0 and results['participants_vs_reviews']['significant']) or \
           (results['comments_vs_reviews']['correlation'] > 0 and results['comments_vs_reviews']['significant']) or \
           (results['review_comments_vs_reviews']['correlation'] > 0 and results['review_comments_vs_reviews']['significant']):
            report.append("\nOs resultados suportam nossa hip√≥tese. Encontramos correla√ß√µes significativas entre as m√©tricas de intera√ß√£o e o n√∫mero de revis√µes. " +
                          "PRs com mais intera√ß√µes t√™m mais revis√µes, possivelmente porque cada revis√£o gera coment√°rios e discuss√µes que podem levar a revis√µes adicionais.")
        else:
            report.append("\nOs resultados n√£o suportam completamente nossa hip√≥tese. As correla√ß√µes entre as m√©tricas de intera√ß√£o e o n√∫mero de revis√µes n√£o foram t√£o fortes ou significativas como esper√°vamos.")
    report.append("\n## Conclus√£o")
    report.append("\nEste estudo analisou a rela√ß√£o entre diversas caracter√≠sticas dos PRs e seu feedback final, bem como o n√∫mero de revis√µes realizadas. Os resultados fornecem insights valiosos sobre como melhorar a chance de aprova√ß√£o de PRs e otimizar o processo de code review em projetos open source.")
    report.append("\nCom base nos resultados, podemos sugerir as seguintes pr√°ticas para melhorar a aprova√ß√£o de PRs:")
    report.append("\n1. Manter os PRs pequenos, afetando poucos arquivos e com poucas linhas alteradas.")
    report.append("2. Incluir descri√ß√µes detalhadas e claras, explicando o prop√≥sito e o contexto do PR.")
    report.append("3. Promover intera√ß√µes construtivas durante o processo de revis√£o, respondendo prontamente aos coment√°rios.")
    report.append("4. Evitar PRs que levem muito tempo para serem analisados, dividindo mudan√ßas grandes em PRs menores e mais focados.")
    report.append("\nEsperamos que estes insights ajudem desenvolvedores e mantenedores de projetos open source a otimizar seus processos de code review, melhorando a qualidade do c√≥digo e a experi√™ncia dos contribuidores.")
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("\n".join(report))
    print(f"üìÑ Relat√≥rio gerado com sucesso em {output_file}")

def main():
    converter_csv_json()

    os.makedirs(DATA_DIR, exist_ok=True)
    visual_dir = os.path.join(DATA_DIR, "visualizations")
    os.makedirs(visual_dir, exist_ok=True)

    csv_path = os.path.join(DATA_DIR, "collected_prs.csv")
    report_path = os.path.join(DATA_DIR, f"report.md")

    print("\nüìÇ Arquivos de Dados e Relat√≥rios")
    print(f"   üìä Arquivo de dados dos PRs a ser analisado: {csv_path}")
    print(f"   üìà Relat√≥rio final ser√° salvo em: {report_path}")
    print(f"   üìä Visualiza√ß√µes ser√£o salvas em: {visual_dir}")

    print("\nüìÇ Diret√≥rios de Salvamento")
    print(f"   üìç Os dados ser√£o salvos no diret√≥rio: {DATA_DIR}")
    print(f"   üìç Caminho para o arquivo de PRs coletados: {csv_path}")
    print(f"   üìç Caminho para o relat√≥rio final: {report_path}")
    print(f"   üìç Caminho para as visualiza√ß√µes: {visual_dir}\n")

    df = load_data(csv_path)
    print(f"üìà Dados carregados com sucesso. Total de {len(df)} PRs.\n")

    all_results = {}
    print("\nüîç Analisando RQ 01: Tamanho vs. Status...")
    all_results["size_vs_status"] = analyze_size_vs_status(df)

    print("\nüîç Analisando RQ 02: Tempo vs. Status...")
    all_results["time_vs_status"] = analyze_time_vs_status(df)

    print("\nüîç Analisando RQ 03: Descri√ß√£o vs. Status...")
    all_results["description_vs_status"] = analyze_description_vs_status(df)

    print("\nüîç Analisando RQ 04: Intera√ß√µes vs. Status...")
    all_results["interactions_vs_status"] = analyze_interactions_vs_status(df)

    print("\nüîç Analisando RQ 05: Tamanho vs. Revis√µes...")
    all_results["size_vs_reviews"] = analyze_size_vs_reviews(df)

    print("\nüîç Analisando RQ 06: Tempo vs. Revis√µes...")
    all_results["time_vs_reviews"] = analyze_time_vs_reviews(df)

    print("\nüîç Analisando RQ 07: Descri√ß√£o vs. Revis√µes...")
    all_results["description_vs_reviews"] = analyze_description_vs_reviews(df)

    print("\nüîç Analisando RQ 08: Intera√ß√µes vs. Revis√µes...")
    all_results["interactions_vs_reviews"] = analyze_interactions_vs_reviews(df)

    print("\nüìë Gerando relat√≥rio final...")
    generate_report(df, all_results, output_file=report_path)

    # Remover colunas tempor√°rias se existirem
    if 'time_bins' in df.columns:
        df.drop(columns=['time_bins'], inplace=True)
    if 'desc_bins' in df.columns:
        df.drop(columns=['desc_bins'], inplace=True)

    print("\nüì¶ Resumo dos arquivos gerados:\n")
    print(f"üîπ {os.path.relpath(csv_path)}")
    print("    ‚Ü™Ô∏è Arquivo CSV contendo todos os Pull Requests analisados (dados brutos, um por linha).")

    print(f"üîπ {os.path.relpath(report_path)}")
    print("    ‚Ü™Ô∏è Relat√≥rio completo em Markdown com todas as an√°lises, gr√°ficos e interpreta√ß√µes.")

    print(f"üîπ {os.path.relpath(visual_dir)}")
    print("    ‚Ü™Ô∏è Pasta com os gr√°ficos PNG gerados para cada pergunta de pesquisa (RQ01 a RQ08).\n")

    print(f"‚úÖ An√°lise conclu√≠da com sucesso! Relat√≥rio salvo em {os.path.relpath(report_path)}")


if __name__ == "__main__":
    main()
    mover_pycache()
