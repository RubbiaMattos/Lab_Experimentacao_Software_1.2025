import os
import sys
import time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from utils import calculate_correlation, interpret_correlation, check_correlation_significance
import base64
from io import BytesIO
import shutil

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "..")))
from config_token import configurar_token

TOKEN = configurar_token()

def format_seconds(seconds):
    return time.strftime('%H:%M:%S', time.gmtime(seconds))

def mover_pycache(destino="Lab3_CodeRevGithub/Lab3S01/__pycache__"):
    for root, dirs, files in os.walk("."):
        if "__pycache__" in dirs:
            origem = os.path.join(root, "__pycache__")
            if os.path.abspath(origem) == os.path.abspath(destino):
                continue  # already in the right place
            os.makedirs(destino, exist_ok=True)
            for arquivo in os.listdir(origem):
                arquivo_destino = os.path.join(destino, arquivo)
                # Force overwrite by removing the existing file before moving
                if os.path.exists(arquivo_destino):
                    os.remove(arquivo_destino)
                shutil.move(os.path.join(origem, arquivo), destino)
            shutil.rmtree(origem)
            print(f"üì¶ Pycache movido para: {destino}")


# Configurar o estilo das visualiza√ß√µes
sns.set(style="whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12

BASE_DIR = os.path.join("Lab3_CodeRevGithub", "Lab3S01")
DATA_DIR = os.path.join(BASE_DIR, "data")
VIS_DIR = os.path.join(DATA_DIR, "visualizations")
os.makedirs(VIS_DIR, exist_ok=True)

collected_path = os.path.join(DATA_DIR, "collected_prs.csv")

def load_data(file_path):
    """
    Carrega os dados dos PRs a partir de um arquivo CSV.
    
    Args:
        file_path (str): Caminho para o arquivo CSV com os dados dos PRs
    
    Returns:
        pd.DataFrame: DataFrame com os dados dos PRs
    """
    df = pd.read_csv(file_path)
    # Limpa e prepara os dados
    df.dropna(subset=["closed_at"], inplace=True)
    # Adiciona coluna com status final (MERGED ou CLOSED)
    df["status"] = df["merged"].apply(lambda x: "MERGED" if x else "CLOSED")
    # Converte datas para datetime
    for col in ["created_at", "closed_at", "merged_at"]:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col])
    return df

def save_figure_to_file(fig, filename, dpi=300):
    """
    Salva uma figura em um arquivo.
    
    Args:
        fig (matplotlib.figure.Figure): Figura a ser salva
        filename (str): Nome do arquivo
        dpi (int): Resolu√ß√£o da imagem
    """
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    fig.savefig(filename, dpi=dpi, bbox_inches='tight')
    print(f"üìÅ Figura salva em {os.path.relpath(filename)}")
    plt.close(fig)

def figure_to_base64(fig):
    """
    Converte uma figura matplotlib para base64 para inclus√£o em markdown.
    
    Args:
        fig (matplotlib.figure.Figure): Figura a ser convertida
    
    Returns:
        str: String base64 da imagem
    """
    buffer = BytesIO()
    fig.savefig(buffer, format='png', dpi=300, bbox_inches='tight')
    buffer.seek(0)
    image_png = buffer.getvalue()
    buffer.close()
    return base64.b64encode(image_png).decode('utf-8')


def create_correlation_heatmap(df, features, target, title):
    """
    Cria um mapa de calor de correla√ß√£o entre v√°rias caracter√≠sticas e um alvo.
    
    Args:
        df (pd.DataFrame): DataFrame com os dados
        features (list): Lista de colunas das caracter√≠sticas
        target (str): Coluna alvo
        title (str): T√≠tulo do gr√°fico
    
    Returns:
        matplotlib.figure.Figure: Figura com o mapa de calor
    """
    corr_data = []
    for feature in features:
        corr_val, p_val = calculate_correlation(df, feature, target, method='spearman')
        significance = '**' if check_correlation_significance(p_val) else ''
        corr_data.append({
            'Feature': feature,
            'Correlation': corr_val,
            'P-value': p_val,
            'Significance': significance
        })
    corr_df = pd.DataFrame(corr_data)
    
    fig, ax = plt.subplots(figsize=(12, len(features) * 0.8 + 2))
    bars = ax.barh(corr_df['Feature'], corr_df['Correlation'],
                    color=corr_df['Correlation'].apply(lambda x: 'skyblue' if x >= 0 else 'salmon'))
    
    for i, bar in enumerate(bars):
        significance = corr_df.iloc[i]['Significance']
        value = corr_df.iloc[i]['Correlation']
        p_value = corr_df.iloc[i]['P-value']
        if value >= 0:
            ax.text(max(value + 0.03, 0.03), i, f'{value:.3f}{significance}\np={p_value:.3e}', va='center')
        else:
            ax.text(min(value - 0.03, -0.03), i, f'{value:.3f}{significance}\np={p_value:.3e}', va='center', ha='right')
    
    ax.axvline(x=0, color='black', linestyle='-', alpha=0.3)
    ax.set_xlim(-1, 1)
    ax.set_xlabel('Coeficiente de correla√ß√£o de Spearman')
    ax.set_title(title)
    fig.text(0.9, 0.1, '** p < 0.05', fontsize=10)
    plt.tight_layout()
    return fig


def create_boxplot(df, x_col, y_col, title, xlabel, ylabel):
    """
    Cria um boxplot para comparar a distribui√ß√£o de uma vari√°vel entre dois grupos.
    
    Args:
        df (pd.DataFrame): DataFrame com os dados
        x_col (str): Coluna para o eixo x (categorias)
        y_col (str): Coluna para o eixo y (valores)
        title (str): T√≠tulo do gr√°fico
        xlabel (str): R√≥tulo do eixo x
        ylabel (str): R√≥tulo do eixo y
    
    Returns:
        matplotlib.figure.Figure: Figura com o boxplot
    """
    fig, ax = plt.subplots()
    sns.boxplot(x=x_col, y=y_col, data=df, ax=ax, palette="Set2")
    sns.stripplot(x=x_col, y=y_col, data=df, ax=ax, size=4, alpha=0.3, jitter=True, color='black')
    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    
    grouped = df.groupby(x_col)[y_col]
    medians = grouped.median()
    for i, (key, median) in enumerate(medians.items()):
        ax.text(i, median * 1.1, f'Mediana: {median:.2f}', ha='center')
    
    groups = [df[df[x_col] == category][y_col].dropna() for category in df[x_col].unique()]
    if len(groups) == 2 and len(groups[0]) > 0 and len(groups[1]) > 0:
        stat, pval = stats.mannwhitneyu(groups[0], groups[1])
        ax.text(0.5, 0.01, f'Teste Mann-Whitney: p={pval:.3e}',
                ha='center', va='bottom', transform=ax.transAxes, fontsize=10,
                bbox=dict(facecolor='white', alpha=0.8))
    plt.tight_layout()
    return fig


def create_scatter_plot(df, x_col, y_col, title, xlabel, ylabel, hue=None, log_scale=False):
    """
    Cria um gr√°fico de dispers√£o entre duas vari√°veis.
    
    Args:
        df (pd.DataFrame): DataFrame com os dados
        x_col (str): Coluna para o eixo x
        y_col (str): Coluna para o eixo y
        title (str): T√≠tulo do gr√°fico
        xlabel (str): R√≥tulo do eixo x
        ylabel (str): R√≥tulo do eixo y
        hue (str, optional): Coluna para colorir os pontos
        log_scale (bool, optional): Se True, aplicar escala logar√≠tmica aos eixos
    
    Returns:
        matplotlib.figure.Figure: Figura com o gr√°fico de dispers√£o
    """
    fig, ax = plt.subplots()
    x_data = df[x_col].copy()
    y_data = df[y_col].copy()
    if x_data.dtype in [np.float64, np.int64] and y_data.dtype in [np.float64, np.int64]:
        x_quantile = np.nanquantile(x_data, 0.99)
        y_quantile = np.nanquantile(y_data, 0.99)
        filtered_df = df[(df[x_col] <= x_quantile) & (df[y_col] <= y_quantile)].copy()
    else:
        filtered_df = df.copy()
    
    if hue:
        sns.scatterplot(x=x_col, y=y_col, data=filtered_df, hue=hue, alpha=0.6, ax=ax)
        plt.legend(title=hue, loc='upper right')
    else:
        sns.scatterplot(x=x_col, y=y_col, data=filtered_df, alpha=0.6, ax=ax)
    
    if log_scale:
        if all(filtered_df[x_col] > 0):
            ax.set_xscale('log')
        if all(filtered_df[y_col] > 0):
            ax.set_yscale('log')
    
    if filtered_df[x_col].dtype in [np.float64, np.int64] and filtered_df[y_col].dtype in [np.float64, np.int64]:
        try:
            x = filtered_df[x_col].values.reshape(-1, 1)
            y = filtered_df[y_col].values
            mask = ~(np.isnan(x.flatten()) | np.isnan(y))
            x = x[mask]
            y = y[mask]
            if len(x) > 1:
                try:
                    from sklearn.linear_model import LinearRegression
                    model = LinearRegression()
                    model.fit(x, y)
                    x_range = np.linspace(min(x), max(x), 100).reshape(-1, 1)
                    y_pred = model.predict(x_range)
                    ax.plot(x_range, y_pred, color='red', linestyle='--')
                    corr_val, p_val = calculate_correlation(filtered_df, x_col, y_col, method='spearman')
                    ax.text(0.05, 0.95, f'Corr. Spearman: {corr_val:.3f}\\np-valor: {p_val:.3e}',
                            transform=ax.transAxes, fontsize=10, va='top',
                            bbox=dict(facecolor='white', alpha=0.8))
                except ImportError:
                    print("Aviso: scikit-learn n√£o instalado; linha de tend√™ncia n√£o adicionada.")
        except Exception as e:
            print(f"Erro ao adicionar linha de tend√™ncia: {e}")
    
    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    plt.tight_layout()
    return fig


def analyze_size_vs_status(df):
    results = {}
    file_status_corr, file_status_pval = calculate_correlation(df, "files_changed", "merged", method='spearman')
    adds_status_corr, adds_status_pval = calculate_correlation(df, "additions", "merged", method='spearman')
    dels_status_corr, dels_status_pval = calculate_correlation(df, "deletions", "merged", method='spearman')
    
    results["files_vs_status"] = {
        "correlation": file_status_corr,
        "p_value": file_status_pval,
        "interpretation": interpret_correlation(file_status_corr),
        "significant": check_correlation_significance(file_status_pval)
    }
    results["additions_vs_status"] = {
        "correlation": adds_status_corr,
        "p_value": adds_status_pval,
        "interpretation": interpret_correlation(adds_status_corr),
        "significant": check_correlation_significance(adds_status_pval)
    }
    results["deletions_vs_status"] = {
        "correlation": dels_status_corr,
        "p_value": dels_status_pval,
        "interpretation": interpret_correlation(dels_status_corr),
        "significant": check_correlation_significance(dels_status_pval)
    }
    
    median_stats = df.groupby("status")[["time_to_close_hours"]].median()
    median_stats["formatted"] = median_stats["time_to_close_hours"].apply(lambda h: format_seconds(h * 3600))
    results["median_stats"] = median_stats

    
    corr_fig = create_correlation_heatmap(df, ["files_changed", "additions", "deletions"], "merged",
                                        "Correla√ß√£o entre Tamanho dos PRs e Status")
    results["correlation_plot"] = figure_to_base64(corr_fig)
    save_figure_to_file(corr_fig, "data/visualizations/rq01_correlation.png")
    
    for col, label in [("files_changed", "N√∫mero de Arquivos"),
                        ("additions", "Linhas Adicionadas"),
                        ("deletions", "Linhas Removidas")]:
        fig = create_boxplot(df, "status", col,
                            f"Distribui√ß√£o de {label} por Status",
                            "Status do PR", label)
        results[f"{col}_boxplot"] = figure_to_base64(fig)
        save_figure_to_file(fig, f"data/visualizations/rq01_{col}_boxplot.png")
    
    return results


def analyze_time_vs_status(df):
    results = {}
    time_status_corr, time_status_pval = calculate_correlation(df, "time_to_close_hours", "merged", method='spearman')
    results["time_vs_status"] = {
        "correlation": time_status_corr,
        "p_value": time_status_pval,
        "interpretation": interpret_correlation(time_status_corr),
        "significant": check_correlation_significance(time_status_pval)
    }
    median_stats = df.groupby("status")[["time_to_close_hours"]].median()
    results["median_stats"] = median_stats
    
    fig = create_boxplot(df, "status", "time_to_close_hours",
                        "Distribui√ß√£o do Tempo de An√°lise por Status",
                        "Status do PR", "Tempo de An√°lise (horas)")
    results["time_boxplot"] = figure_to_base64(fig)
    save_figure_to_file(fig, "data/visualizations/rq02_time_boxplot.png")
    
    fig, ax = plt.subplots()
    for status, color in zip(["MERGED", "CLOSED"], ["green", "red"]):
        subset = df[df["status"] == status]["time_to_close_hours"].dropna()
        cutoff = np.percentile(subset, 95)
        sns.histplot(subset[subset <= cutoff], ax=ax, color=color, alpha=0.5, label=status, kde=True)
    ax.set_title("Distribui√ß√£o do Tempo de An√°lise por Status")
    ax.set_xlabel("Tempo de An√°lise (horas)")
    ax.set_ylabel("Contagem")
    ax.legend()
    results["time_histogram"] = figure_to_base64(fig)
    save_figure_to_file(fig, "data/visualizations/rq02_time_histogram.png")
    
    return results


def analyze_description_vs_status(df):
    results = {}
    desc_status_corr, desc_status_pval = calculate_correlation(df, "body_length", "merged", method='spearman')
    results["description_vs_status"] = {
        "correlation": desc_status_corr,
        "p_value": desc_status_pval,
        "interpretation": interpret_correlation(desc_status_corr),
        "significant": check_correlation_significance(desc_status_pval)
    }
    median_stats = df.groupby("status")[["body_length"]].median()
    results["median_stats"] = median_stats
    
    fig = create_boxplot(df, "status", "body_length",
                        "Distribui√ß√£o do Tamanho da Descri√ß√£o por Status",
                        "Status do PR", "Tamanho da Descri√ß√£o (caracteres)")
    results["description_boxplot"] = figure_to_base64(fig)
    save_figure_to_file(fig, "data/visualizations/rq03_description_boxplot.png")
    
    fig, ax = plt.subplots()
    medians = df.groupby("status")["body_length"].median()
    bars = ax.bar(medians.index, medians.values, color=["green", "red"])
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2., height * 1.01,
                f'{height:.1f}', ha='center', va='bottom')
    ax.set_title("Mediana do Tamanho da Descri√ß√£o por Status")
    ax.set_xlabel("Status do PR")
    ax.set_ylabel("Tamanho Mediano da Descri√ß√£o (caracteres)")
    results["description_bars"] = figure_to_base64(fig)
    save_figure_to_file(fig, "data/visualizations/rq03_description_bars.png")
    
    return results


def analyze_interactions_vs_status(df):
    results = {}
    part_status_corr, part_status_pval = calculate_correlation(df, "participant_count", "merged", method='spearman')
    comm_status_corr, comm_status_pval = calculate_correlation(df, "comments", "merged", method='spearman')
    rev_comm_status_corr, rev_comm_status_pval = calculate_correlation(df, "review_comments", "merged", method='spearman')
    
    results["participants_vs_status"] = {
        "correlation": part_status_corr,
        "p_value": part_status_pval,
        "interpretation": interpret_correlation(part_status_corr),
        "significant": check_correlation_significance(part_status_pval)
    }
    results["comments_vs_status"] = {
        "correlation": comm_status_corr,
        "p_value": comm_status_pval,
        "interpretation": interpret_correlation(comm_status_corr),
        "significant": check_correlation_significance(comm_status_pval)
    }
    results["review_comments_vs_status"] = {
        "correlation": rev_comm_status_corr,
        "p_value": rev_comm_status_pval,
        "interpretation": interpret_correlation(rev_comm_status_corr),
        "significant": check_correlation_significance(rev_comm_status_pval)
    }
    median_stats = df.groupby("status")[["participant_count", "comments", "review_comments"]].median()
    results["median_stats"] = median_stats
    
    corr_fig = create_correlation_heatmap(df, ["participant_count", "comments", "review_comments"], "merged",
                                        "Correla√ß√£o entre Intera√ß√µes e Status")
    results["correlation_plot"] = figure_to_base64(corr_fig)
    save_figure_to_file(corr_fig, "data/visualizations/rq04_correlation.png")
    
    for col, label in [("participant_count", "N√∫mero de Participantes"),
                        ("comments", "N√∫mero de Coment√°rios"),
                        ("review_comments", "N√∫mero de Coment√°rios de Revis√£o")]:
        fig = create_boxplot(df, "status", col,
                            f"Distribui√ß√£o de {label} por Status",
                            "Status do PR", label)
        results[f"{col}_boxplot"] = figure_to_base64(fig)
        save_figure_to_file(fig, f"data/visualizations/rq04_{col}_boxplot.png")
    
    return results


def analyze_size_vs_reviews(df):
    results = {}
    file_rev_corr, file_rev_pval = calculate_correlation(df, "files_changed", "review_count", method='spearman')
    adds_rev_corr, adds_rev_pval = calculate_correlation(df, "additions", "review_count", method='spearman')
    dels_rev_corr, dels_rev_pval = calculate_correlation(df, "deletions", "review_count", method='spearman')
    
    results["files_vs_reviews"] = {
        "correlation": file_rev_corr,
        "p_value": file_rev_pval,
        "interpretation": interpret_correlation(file_rev_corr),
        "significant": check_correlation_significance(file_rev_pval)
    }
    results["additions_vs_reviews"] = {
        "correlation": adds_rev_corr,
        "p_value": adds_rev_pval,
        "interpretation": interpret_correlation(adds_rev_corr),
        "significant": check_correlation_significance(adds_rev_pval)
    }
    results["deletions_vs_reviews"] = {
        "correlation": dels_rev_corr,
        "p_value": dels_rev_pval,
        "interpretation": interpret_correlation(dels_rev_corr),
        "significant": check_correlation_significance(dels_rev_pval)
    }
    
    corr_fig = create_correlation_heatmap(df, ["files_changed", "additions", "deletions"], "review_count",
                                        "Correla√ß√£o entre Tamanho dos PRs e N√∫mero de Revis√µes")
    results["correlation_plot"] = figure_to_base64(corr_fig)
    save_figure_to_file(corr_fig, "data/visualizations/rq05_correlation.png")
    
    for col, label in [("files_changed", "N√∫mero de Arquivos"),
                        ("additions", "Linhas Adicionadas"),
                        ("deletions", "Linhas Removidas")]:
        fig = create_scatter_plot(df, col, "review_count",
                                f"Rela√ß√£o entre {label} e N√∫mero de Revis√µes",
                                label, "N√∫mero de Revis√µes", log_scale=True)
        results[f"{col}_scatter"] = figure_to_base64(fig)
        save_figure_to_file(fig, f"data/visualizations/rq05_{col}_scatter.png")
    
    return results


def analyze_time_vs_reviews(df):
    results = {}
    time_rev_corr, time_rev_pval = calculate_correlation(df, "time_to_close_hours", "review_count", method='spearman')
    results["time_vs_reviews"] = {
        "correlation": time_rev_corr,
        "p_value": time_rev_pval,
        "interpretation": interpret_correlation(time_rev_corr),
        "significant": check_correlation_significance(time_rev_pval)
    }
    
    fig = create_scatter_plot(df, "time_to_close_hours", "review_count",
                                "Rela√ß√£o entre Tempo de An√°lise e N√∫mero de Revis√µes",
                                "Tempo de An√°lise (horas)", "N√∫mero de Revis√µes", log_scale=True)
    results["time_scatter"] = figure_to_base64(fig)
    save_figure_to_file(fig, "data/visualizations/rq06_time_scatter.png")
    
    fig, ax = plt.subplots()
    df['time_bins'] = pd.cut(df['time_to_close_hours'],
                            bins=[0, 24, 48, 72, 168, df['time_to_close_hours'].max()],
                            labels=['0-24h', '24-48h', '48-72h', '72h-1 semana', '> 1 semana'])
    time_bin_means = df.groupby('time_bins', observed=False)['review_count'].mean().reset_index()
    time_bin_counts = df.groupby('time_bins', observed=False).size().reset_index(name='count')
    time_bin_data = pd.merge(time_bin_means, time_bin_counts, on='time_bins')
    ax.plot(time_bin_data['time_bins'], time_bin_data['review_count'], marker='o', linestyle='-')
    for i, row in time_bin_data.iterrows():
        ax.annotate(f"n={row['count']}", (i, row['review_count']),
                    textcoords="offset points", xytext=(0, 10), ha='center')
    ax.set_title("M√©dia de Revis√µes por Faixa de Tempo")
    ax.set_xlabel("Tempo de An√°lise")
    ax.set_ylabel("M√©dia de Revis√µes")
    plt.xticks(rotation=45)
    plt.tight_layout()
    results["time_bins_plot"] = figure_to_base64(fig)
    save_figure_to_file(fig, "data/visualizations/rq06_time_bins.png")
    
    return results


def analyze_description_vs_reviews(df):
    results = {}
    desc_rev_corr, desc_rev_pval = calculate_correlation(df, "body_length", "review_count", method='spearman')
    results["description_vs_reviews"] = {
        "correlation": desc_rev_corr,
        "p_value": desc_rev_pval,
        "interpretation": interpret_correlation(desc_rev_corr),
        "significant": check_correlation_significance(desc_rev_pval)
    }
    
    fig = create_scatter_plot(df, "body_length", "review_count",
                            "Rela√ß√£o entre Tamanho da Descri√ß√£o e N√∫mero de Revis√µes",
                            "Tamanho da Descri√ß√£o (caracteres)", "N√∫mero de Revis√µes", log_scale=True)
    results["description_scatter"] = figure_to_base64(fig)
    save_figure_to_file(fig, "data/visualizations/rq07_description_scatter.png")
    
    fig, ax = plt.subplots()
    df['desc_bins'] = pd.cut(df['body_length'],
                            bins=[0, 100, 500, 1000, 2000, df['body_length'].max()],
                            labels=['0-100', '100-500', '500-1000', '1000-2000', '> 2000'])
    desc_bin_means = df.groupby('desc_bins', observed=False)['review_count'].mean().reset_index()
    desc_bin_counts = df.groupby('desc_bins', observed=False).size().reset_index(name='count')
    desc_bin_data = pd.merge(desc_bin_means, desc_bin_counts, on='desc_bins')
    bars = ax.bar(desc_bin_data['desc_bins'], desc_bin_data['review_count'])
    for i, bar in enumerate(bars):
        height = bar.get_height()
        count = desc_bin_data.iloc[i]['count']
        ax.text(bar.get_x() + bar.get_width() / 2., height + 0.1, f"n={count}", ha='center', va='bottom')
    ax.set_title("M√©dia de Revis√µes por Tamanho de Descri√ß√£o")
    ax.set_xlabel("Tamanho da Descri√ß√£o (caracteres)")
    ax.set_ylabel("M√©dia de Revis√µes")
    plt.xticks(rotation=45)
    plt.tight_layout()
    results["desc_bins_plot"] = figure_to_base64(fig)
    save_figure_to_file(fig, "data/visualizations/rq07_desc_bins.png")
    
    return results


def analyze_interactions_vs_reviews(df):
    results = {}
    part_rev_corr, part_rev_pval = calculate_correlation(df, "participant_count", "review_count", method='spearman')
    comm_rev_corr, comm_rev_pval = calculate_correlation(df, "comments", "review_count", method='spearman')
    rev_comm_rev_corr, rev_comm_rev_pval = calculate_correlation(df, "review_comments", "review_count", method='spearman')
    
    results["participants_vs_reviews"] = {
        "correlation": part_rev_corr,
        "p_value": part_rev_pval,
        "interpretation": interpret_correlation(part_rev_corr),
        "significant": check_correlation_significance(part_rev_pval)
    }
    results["comments_vs_reviews"] = {
        "correlation": comm_rev_corr,
        "p_value": comm_rev_pval,
        "interpretation": interpret_correlation(comm_rev_corr),
        "significant": check_correlation_significance(comm_rev_pval)
    }
    results["review_comments_vs_reviews"] = {
        "correlation": rev_comm_rev_corr,
        "p_value": rev_comm_rev_pval,
        "interpretation": interpret_correlation(rev_comm_rev_corr),
        "significant": check_correlation_significance(rev_comm_rev_pval)
    }
    
    corr_fig = create_correlation_heatmap(df, ["participant_count", "comments", "review_comments"],
                                        "review_count", "Correla√ß√£o entre Intera√ß√µes e N√∫mero de Revis√µes")
    results["correlation_plot"] = figure_to_base64(corr_fig)
    save_figure_to_file(corr_fig, "data/visualizations/rq08_correlation.png")
    
    for col, label in [("participant_count", "N√∫mero de Participantes"),
                        ("comments", "N√∫mero de Coment√°rios"),
                        ("review_comments", "N√∫mero de Coment√°rios de Revis√£o")]:
        fig = create_scatter_plot(df, col, "review_count",
                                f"Rela√ß√£o entre {label} e N√∫mero de Revis√µes",
                                label, "N√∫mero de Revis√µes")
        results[f"{col}_scatter"] = figure_to_base64(fig)
        save_figure_to_file(fig, f"data/visualizations/rq08_{col}_scatter.png")
    
    return results


def generate_report(all_results, output_file="report.md"):
    os.makedirs("data/visualizations", exist_ok=True)
    report = []
    
    # T√≠tulo
    report.append("üìÑ **Relat√≥rio de An√°lise da Atividade de Code Review no GitHub**\n")
    
    # Introdu√ß√£o
    report.append("\n## üìã **Introdu√ß√£o**\n")
    report.append("    Este relat√≥rio apresenta os resultados da an√°lise da atividade de code review em reposit√≥rios populares do GitHub. O objetivo √© identificar vari√°veis que influenciam no merge de um PR, sob a perspectiva de desenvolvedores que submetem c√≥digo aos reposit√≥rios selecionados.\n")
    
    report.append("\n### ‚ú® **Hip√≥teses Informais**\n")
    report.append("    1. PRs menores t√™m maior probabilidade de serem aprovados. ‚úÇÔ∏è\n")
    report.append("    2. PRs que levam mais tempo para serem analisados t√™m menor probabilidade de serem aprovados. ‚è≥‚ùå\n")
    report.append("    3. PRs com descri√ß√µes mais detalhadas t√™m maior probabilidade de serem aprovados. üìëüëç\n")
    report.append("    4. PRs com mais intera√ß√µes t√™m maior probabilidade de serem aprovados. üí¨üîÑ\n")
    report.append("    5. PRs maiores requerem mais revis√µes. üìÇüîç\n")
    report.append("    6. PRs que levam mais tempo para serem analisados t√™m mais revis√µes. ‚è±Ô∏èüîÑ\n")
    report.append("    7. PRs com descri√ß√µes mais detalhadas t√™m menos revis√µes. ‚úçÔ∏èüìâ\n")
    report.append("    8. PRs com mais intera√ß√µes t√™m mais revis√µes. üí¨üîÑ‚úÖ\n")
    
    # Metodologia
    report.append("\n## üßë‚Äçüî¨ **Metodologia**\n")
    report.append("    Para realizar esta an√°lise, seguimos os seguintes passos:\n")
    report.append("    1. **Coleta de dados**: Selecionamos os 200 reposit√≥rios mais populares do GitHub com pelo menos 100 PRs (MERGED + CLOSED). üìäüìà\n")
    report.append("    2. **Filtragem dos dados**: Selecionamos apenas PRs com status MERGED ou CLOSED, que possu√≠am pelo menos uma revis√£o e cuja an√°lise levou pelo menos uma hora. ‚è±Ô∏è‚úÖ\n")
    report.append("    3. **An√°lise estat√≠stica**: Utilizamos o coeficiente de correla√ß√£o de Spearman para analisar as rela√ß√µes entre as vari√°veis, pois esse m√©todo n√£o assume que os dados seguem uma distribui√ß√£o normal e √© menos sens√≠vel a outliers. üîçüìâ\n")
    report.append("    4. **Interpreta√ß√£o dos resultados**: Interpretamos os coeficientes de correla√ß√£o da seguinte forma: üéØüìä\n")
    report.append("        - |r| < 0.1: Correla√ß√£o insignificante üî¥\n")
    report.append("        - 0.1 ‚â§ |r| < 0.3: Correla√ß√£o fraca üü†\n")
    report.append("        - 0.3 ‚â§ |r| < 0.5: Correla√ß√£o moderada üü°\n")
    report.append("        - 0.5 ‚â§ |r| < 0.7: Correla√ß√£o forte üü¢\n")
    report.append("        - |r| ‚â• 0.7: Correla√ß√£o muito forte üîµ\n")
    report.append("\n    Consideramos correla√ß√µes estatisticamente significativas aquelas com p-valor < 0.05. üîíüí°")
    
    # Resultados
    report.append("\n## üìä **Resultados**\n")
    
    # RQ 01: Tamanho dos PRs
    report.append("\n### RQ 01: Rela√ß√£o entre o tamanho dos PRs e o feedback final das revis√µes\n")
    if "size_vs_status" in all_results:
        results = all_results["size_vs_status"]
        report.append("    **üìè Correla√ß√£o entre m√©tricas de tamanho e status:**\n")
        report.append(f"    ![Correla√ß√£o entre Tamanho dos PRs e Status](data/visualizations/rq01_correlation.png) üìà")
        report.append("    **üìÇ Correla√ß√£o entre n√∫mero de arquivos alterados e status:**\n")
        report.append(f"    - Coeficiente de correla√ß√£o: {results['files_vs_status']['correlation']:.4f} üî¢")
        report.append(f"    - P-valor: {results['files_vs_status']['p_value']:.4e} üîç")
        report.append(f"    - Interpreta√ß√£o: {results['files_vs_status']['interpretation']} üìä")
        report.append(f"    - Estatisticamente significativo: {'‚úÖ Sim' if results['files_vs_status']['significant'] else '‚ùå N√£o'}")
        report.append(f"    ![Distribui√ß√£o de Arquivos por Status](data/visualizations/rq01_files_changed_boxplot.png) üìä")
    
    # RQ 02: Tempo de An√°lise
    report.append("\n### RQ 02: Rela√ß√£o entre o tempo de an√°lise dos PRs e o feedback final das revis√µes\n")
    if "time_vs_status" in all_results:
        results = all_results["time_vs_status"]
        report.append("    **‚è±Ô∏è Correla√ß√£o entre tempo de an√°lise e status:**\n")
        report.append(f"    - Coeficiente de correla√ß√£o: {results['time_vs_status']['correlation']:.4f} üî¢")
        report.append(f"    - P-valor: {results['time_vs_status']['p_value']:.4e} üîç")
        report.append(f"    - Interpreta√ß√£o: {results['time_vs_status']['interpretation']} üìä")
        report.append(f"    - Estatisticamente significativo: {'‚úÖ Sim' if results['time_vs_status']['significant'] else '‚ùå N√£o'}")
        report.append(f"    ![Distribui√ß√£o do Tempo de An√°lise por Status](data/visualizations/rq02_time_boxplot.png) ‚è±Ô∏è")
        report.append(f"    ![Histograma do Tempo de An√°lise por Status](data/visualizations/rq02_time_histogram.png) üìä")
        if "median_stats" in results:
            report.append(f"\n    **‚è±Ô∏è Tempo Mediano de An√°lise por Status:**")
            for status, row in results["median_stats"].iterrows():
                horas = row["time_to_close_hours"]
                tempo_formatado = format_seconds(horas * 3600)
                report.append(f"    - {status}: {tempo_formatado} (‚âà {horas:.2f}h)")

    
    # RQ 03: Descri√ß√£o dos PRs
    report.append("\n### RQ 03: Rela√ß√£o entre a descri√ß√£o dos PRs e o feedback final das revis√µes\n")
    if "description_vs_status" in all_results:
        results = all_results["description_vs_status"]
        report.append("    **üìÑ Correla√ß√£o entre tamanho da descri√ß√£o e status:**\n")
        report.append(f"    - Coeficiente de correla√ß√£o: {results['description_vs_status']['correlation']:.4f} üî¢")
        report.append(f"    - P-valor: {results['description_vs_status']['p_value']:.4e} üîç")
        report.append(f"    - Interpreta√ß√£o: {results['description_vs_status']['interpretation']} üìä")
        report.append(f"    - Estatisticamente significativo: {'‚úÖ Sim' if results['description_vs_status']['significant'] else '‚ùå N√£o'}")
        report.append(f"    ![Distribui√ß√£o do Tamanho da Descri√ß√£o por Status](data/visualizations/rq03_description_boxplot.png) üìä")
        report.append(f"    ![Mediana do Tamanho da Descri√ß√£o por Status](data/visualizations/rq03_description_bars.png) üìä")
    
    # Discuss√£o
    report.append("\n## üìù **Discuss√£o**\n")
    report.append("    Nesta se√ß√£o, discutimos os resultados obtidos em rela√ß√£o √†s nossas hip√≥teses iniciais.\n")
    report.append("\n### RQ 01: Rela√ß√£o entre o tamanho dos PRs e o feedback final das revis√µes\n")
    report.append("    **Hip√≥tese:** PRs menores t√™m maior probabilidade de serem aprovados. ‚úÇÔ∏èüìà")
    if "size_vs_status" in all_results:
        results = all_results["size_vs_status"]
        if results['files_vs_status']['correlation'] < 0 and results['files_vs_status']['significant']:
            report.append("\n    üü¢ **Os resultados suportam nossa hip√≥tese.** Encontramos uma correla√ß√£o " +
                        results['files_vs_status']['interpretation'].lower() +
                        " e estatisticamente significativa entre o n√∫mero de arquivos alterados e a aprova√ß√£o do PR. " +
                        "PRs com menos arquivos alterados t√™m maior probabilidade de serem aprovados. ‚úÖ")
        else:
            report.append("\n    üî¥ **Os resultados n√£o suportam completamente nossa hip√≥tese.** A correla√ß√£o entre o tamanho do PR e sua aprova√ß√£o n√£o foi t√£o forte ou significativa como esper√°vamos. ‚ùå")
    
    # Conclus√£o
    report.append("\n## üîç **Conclus√£o**\n")
    report.append("\n    Este estudo analisou a rela√ß√£o entre diversas caracter√≠sticas dos PRs e seu feedback final, bem como o n√∫mero de revis√µes realizadas. Os resultados fornecem insights valiosos sobre como melhorar a chance de aprova√ß√£o de PRs e otimizar o processo de code review em projetos open source. üöÄ")
    report.append("\n    Com base nos resultados, podemos sugerir as seguintes pr√°ticas para melhorar a aprova√ß√£o de PRs:\n")
    report.append("    1. Manter os PRs pequenos, afetando poucos arquivos e com poucas linhas alteradas. ‚úÇÔ∏è\n")
    report.append("    2. Incluir descri√ß√µes detalhadas e claras, explicando o prop√≥sito e o contexto do PR. üìù\n")
    report.append("    3. Promover intera√ß√µes construtivas durante o processo de revis√£o, respondendo prontamente aos coment√°rios. üí¨\n")
    report.append("    4. Evitar PRs que levem muito tempo para serem analisados, dividindo mudan√ßas grandes em PRs menores e mais focados. ‚è≥\n")
    report.append("\n    üéØ **Esperamos que estes insights ajudem desenvolvedores e mantenedores de projetos open source a otimizar seus processos de code review, melhorando a qualidade do c√≥digo e a experi√™ncia dos contribuidores.**")
    
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("\n".join(report))
    print(f"üìÑ **Relat√≥rio gerado com sucesso em** {output_file}")

def main():
    # Caminho da pasta atual (Lab3S01/scripts/)
    base_dir = os.path.join("Lab3_CodeRevGithub", "Lab3S01")
    data_dir = os.path.join(base_dir, "data")
    visual_dir = os.path.join(data_dir, "visualizations")

    # Garantir que o diret√≥rio de visualiza√ß√µes exista
    os.makedirs(visual_dir, exist_ok=True)

    # Caminho para salvar o arquivo CSV com os PRs coletados
    csv_path = os.path.join(data_dir, "collected_prs.csv")
    report_path = os.path.join(data_dir, "report.md")

    # Imprimir o caminho onde os dados ser√£o salvos
    print("üìÇ Arquivos de Dados e Relat√≥rios\n")
    print(f"   üìä Arquivo de dados dos PRs a ser analisado: {csv_path}")
    print(f"   üìà Relat√≥rio final ser√° salvo em: {report_path}")
    print(f"   üìä Visualiza√ß√µes ser√£o salvas em: {visual_dir}\n")

    print("üìÇ Diret√≥rios de Salvamento\n")
    print(f"   üìç Os dados ser√£o salvos no diret√≥rio: {data_dir}")
    print(f"   üìç Caminho para o arquivo de PRs coletados: {csv_path}")
    print(f"   üìç Caminho para o relat√≥rio final: {report_path}")
    print(f"   üìç Caminho para as visualiza√ß√µes: {visual_dir}\n")

    # Carregar dados
    df = load_data(csv_path)
    print(f"üìà Dados carregados com sucesso. Total de {len(df)} PRs.\n")

    # Executar todas as an√°lises
    all_results = {}
    print("üîç Analisando RQ 01: Tamanho vs. Status...")
    all_results["size_vs_status"] = analyze_size_vs_status(df)

    print("üîç Analisando RQ 02: Tempo vs. Status...")
    all_results["time_vs_status"] = analyze_time_vs_status(df)

    print("üîç Analisando RQ 03: Descri√ß√£o vs. Status...")
    all_results["description_vs_status"] = analyze_description_vs_status(df)

    print("üîç Analisando RQ 04: Intera√ß√µes vs. Status...")
    all_results["interactions_vs_status"] = analyze_interactions_vs_status(df)

    print("üîç Analisando RQ 05: Tamanho vs. Revis√µes...")
    all_results["size_vs_reviews"] = analyze_size_vs_reviews(df)

    print("üîç Analisando RQ 06: Tempo vs. Revis√µes...")
    all_results["time_vs_reviews"] = analyze_time_vs_reviews(df)

    print("üîç Analisando RQ 07: Descri√ß√£o vs. Revis√µes...")
    all_results["description_vs_reviews"] = analyze_description_vs_reviews(df)

    print("üîç Analisando RQ 08: Intera√ß√µes vs. Revis√µes...")
    all_results["interactions_vs_reviews"] = analyze_interactions_vs_reviews(df)

    print("üìë Gerando relat√≥rio final...")
    generate_report(all_results, output_file=report_path)

    # ‚úÖ Descri√ß√£o final dos arquivos gerados
    print("\nüì¶ Resumo dos arquivos gerados:\n")
    print(f"üîπ {os.path.relpath(csv_path)}")
    print("    ‚Ü™Ô∏è Arquivo CSV contendo todos os Pull Requests analisados (dados brutos, um por linha).")
    
    print(f"üîπ {os.path.relpath(report_path)}")
    print("    ‚Ü™Ô∏è Relat√≥rio completo em Markdown com todas as an√°lises, gr√°ficos e interpreta√ß√µes.")

    print(f"üîπ {os.path.relpath(visual_dir)}")
    print("    ‚Ü™Ô∏è Pasta com os gr√°ficos PNG gerados para cada pergunta de pesquisa (RQ01 a RQ08).\n")

    print(f"‚úÖ An√°lise conclu√≠da com sucesso! Relat√≥rio salvo em {os.path.relpath(report_path)}")

if __name__ == "__main__":
    main()
