"""
An√°lise de Reposit√≥rios Populares do GitHub

Este script realiza uma an√°lise detalhada dos reposit√≥rios mais populares do GitHub,
coletando dados atrav√©s da API GraphQL do GitHub e gerando relat√≥rios estat√≠sticos.

Autores:
    - Nataniel Geraldo Mendes Peixoto
    - Nelson de Campos Nolasco
    - Rubia Coelho de Matos

Data: 23 fevereiro/2025

Depend√™ncias:
    - pandas: para manipula√ß√£o e an√°lise de dados em Python.
    - requests: faz requisi√ß√µes HTTP.
    - matplotlib: para cria√ß√£o de gr√°ficos e visualiza√ß√µes.
    - seaborn: visualiza√ß√£o estat√≠stica baseada no Matplotlib, oferece uma interface amig√°vel e gr√°ficos atraentes.
    - python-dotenv: permite carregar vari√°veis de ambiente a partir de um arquivo .env.config.
    - os: fornece fun√ß√µes para interagir com o sistema operacional.
    - time: fornece v√°rias fun√ß√µes para trabalhar com tempo.

"""

import os
import time
import pandas as pd
import requests
from dotenv import load_dotenv


# üîπ Diret√≥rio do script atual
script_dir = os.path.dirname(os.path.abspath(__file__))

# üîπ Subir um n√≠vel para tentar encontrar o Lab1_RepoPop
repo_root = os.path.abspath(os.path.join(script_dir, ".."))  # Volta um n√≠vel

# üîπ Caminho din√¢mico do .env.config
env_path = os.path.join(repo_root, ".env.config")

# üîπ Verificar se o arquivo existe antes de carregar
if os.path.exists(env_path):
    load_dotenv(dotenv_path=env_path)
    print(f"‚úÖ Arquivo .env.config carregado de: {env_path}")
else:
    raise FileNotFoundError(f"‚ùå ERRO: O arquivo .env.config N√ÉO foi encontrado no caminho esperado: {env_path}")

# üîπ Testar se o token foi carregado corretamente
TOKEN = os.getenv("GITHUB_TOKEN")

if TOKEN:
    print("‚úÖ Token carregado com sucesso!")
else:
    raise ValueError("‚ùå ERRO: Token GITHUB_TOKEN n√£o foi encontrado no .env.config")


# üîπ Define diret√≥rio de sa√≠da para os arquivos gerados
output_dir = os.path.join(os.getcwd(), "Relat√≥rios")


class GitHubDataCollector:
    """
        Classe respons√°vel pela coleta dos dados de reposit√≥rios do GitHub usando a API GraphQL.

        A classe utiliza a API GraphQL do GitHub para coletar informa√ß√µes detalhadas sobre
        os reposit√≥rios mais populares, incluindo estat√≠sticas de stars, linguagens,
        contribui√ß√µes e issues.

        Atributos:
            url (str): URL da API GraphQL do GitHub
            headers (dict): Cabe√ßalhos HTTP incluindo o token de autentica√ß√£o
        """
    def __init__(self, token):
        """
                Inicializa o coletor com um token de autentica√ß√£o do GitHub.

                Args:
                    token (str): Token de autentica√ß√£o do GitHub para acesso √† API
        """
        self.url = 'https://api.github.com/graphql'
        self.headers = {
            'Authorization': f'bearer {token}',
            'Content-Type': 'application/json',
        }

    def get_top_repos(self, limit=1000):
        """
                Coleta dados dos reposit√≥rios mais populares do GitHub.

                Realiza consultas paginadas √† API GraphQL do GitHub para coletar informa√ß√µes
                dos reposit√≥rios com mais de 100 stars.

                Args:
                    limit (int): N√∫mero m√°ximo de reposit√≥rios a serem coletados (default: 100)

                Returns:
                    list: Lista de dicion√°rios contendo dados dos reposit√≥rios

                Raises:
                    Exception: Se houver erro na comunica√ß√£o com a API ou no processamento dos dados
        """
        query = """
        query($cursor: String) {
          search(query: "stars:>100", type: REPOSITORY, first: 25, after: $cursor) {
            pageInfo {
              hasNextPage
              endCursor
            }
            nodes {
              ... on Repository {
                nameWithOwner
                url
                stargazerCount
                primaryLanguage {
                  name
                }
                createdAt
                updatedAt
                defaultBranchRef {
                  name
                }
                releases {
                  totalCount
                }
                pullRequests(states: MERGED) {
                  totalCount
                }
                issues(states: [OPEN, CLOSED]) {
                  totalCount
                }
                closedIssues: issues(states: CLOSED) {
                  totalCount
                }
              }
            }
          }
        }
        """

        repos_data = []
        cursor = None

        print("\nüîπ Iniciando coleta de reposit√≥rios...")

        while len(repos_data) < limit:
            try:
                variables = {"cursor": cursor}
                response = requests.post(
                    self.url,
                    headers=self.headers,
                    json={'query': query, 'variables': variables}
                )

                print(f"Status da resposta: {response.status_code}")

                if response.status_code != 200:
                    print(f"‚ùå Erro na requisi√ß√£o: {response.text}")
                    break

                result = response.json()

                if 'errors' in result:
                    print(f"‚ùå Erros GraphQL: {result['errors']}")
                    break

                if 'data' not in result:
                    print(f"‚ùå Resposta sem dados: {result}")
                    break

                current_repos = result['data']['search']['nodes']
                if not current_repos:
                    break

                repos_data.extend(current_repos)
                print(f"Reposit√≥rios coletados at√© agora: {len(repos_data)}")

                page_info = result['data']['search']['pageInfo']
                if not page_info['hasNextPage']:
                    break

                cursor = page_info['endCursor']
                time.sleep(2)  # Respeitar limite de taxa

            except Exception as e:
                print(f"Erro durante a coleta: {str(e)}")
                print(f"Resposta completa: {response.text if 'response' in locals() else 'No response'}")
                break

        return repos_data[:limit]


def analyze_data(repos_data):
    """
        Analisa os dados coletados dos reposit√≥rios, calculando m√©tricas solicitadas.

        Processa os dados brutos dos reposit√≥rios, calculando m√©tricas derivadas como
        idade do reposit√≥rio, tempo desde √∫ltima atualiza√ß√£o e taxa de resolu√ß√£o de issues.

        Args:
            repos_data (list): Lista de dicion√°rios com dados dos reposit√≥rios

        Returns:
            pandas.DataFrame: DataFrame contendo os dados analisados e m√©tricas calculadas
    """
    # Converte para DataFrame
    df = pd.DataFrame(repos_data)

    # Converte as datas para UTC
    df['createdAt'] = pd.to_datetime(df['createdAt']).dt.tz_convert('UTC')
    df['updatedAt'] = pd.to_datetime(df['updatedAt']).dt.tz_convert('UTC')
    now = pd.Timestamp.now(tz='UTC')

    # Calcula m√©tricas
    df['age_days'] = (now - df['createdAt']).dt.total_seconds() / (24 * 60 * 60)
    df['days_since_update'] = (now - df['updatedAt']).dt.total_seconds() / (24 * 60 * 60)
    df['language'] = df['primaryLanguage'].apply(lambda x: x['name'] if x else 'None')

    # Calcula raz√£o de issues fechadas
    df['issues_closed_ratio'] = df.apply(
        lambda row: row['closedIssues']['totalCount'] / row['issues']['totalCount']
        if row['issues']['totalCount'] > 0 else 0,
        axis=1
    )

    return df


def generate_research_report(df):
    """
        Gera um relat√≥rio de pesquisa detalhado com base nos dados analisados.

        Limpa os NONE que apareceram numa primeira pesquisa para se ter resultados mais
        pr√≥ximos do que √© pedido
        Analisa diferentes aspectos dos reposit√≥rios populares por meio de questions de
        pesquisa (RQs) espec√≠ficas, gerando visualiza√ß√µes e m√©tricas estat√≠sticas.

        Args:
            df (pandas.DataFrame): DataFrame contendo os dados analisados

        Outputs:
            - Imprime resultados estat√≠sticos na tela
            - Gera e salva gr√°fico de barras das linguagens mais populares
            - Fornece an√°lises detalhadas para cada RQ
    """
    print("\nRESULTADOS DA PESQUISA:")

    # RQ 01
    print("\nRQ 01. Sistemas populares s√£o maduros/antigos?")
    idade_media = df['age_days'].mean() / 365.25
    idade_mediana = df['age_days'].median() / 365.25
    print(f"Idade m√©dia dos reposit√≥rios: {idade_media:.2f} anos")
    print(f"Mediana da idade: {idade_mediana:.2f} anos")

    # RQ 02

    print("\nRQ 02. Sistemas populares recebem muita contribui√ß√£o externa?")
    try:
        prs_mean = df['pullRequests'].apply(lambda x: x['totalCount']).mean()
        prs_median = df['pullRequests'].apply(lambda x: x['totalCount']).median()
        print(f"M√©dia de PRs aceitas: {prs_mean:.2f}")
        print(f"Mediana de PRs aceitas: {prs_median:.2f}")

        import seaborn as sns
        import matplotlib.pyplot as plt

        # Extrai a contagem de PRs aceitos
        df['pr_count'] = df['pullRequests'].apply(lambda x: x['totalCount'])

        # Configura√ß√£o do gr√°fico
        plt.figure(figsize=(8, 6))
        sns.boxplot(y=df['pr_count'], color="skyblue")

        # T√≠tulos e r√≥tulos
        plt.title("Distribui√ß√£o do N√∫mero de PRs Aceitos", fontsize=14)
        plt.ylabel("Quantidade de PRs Aceitos")

        # Salva o gr√°fico
        plt.savefig(os.path.join(output_dir, 'qtd_PRs_aceitos.png'), dpi=300, bbox_inches='tight')
        print("\nGr√°fico salvo como 'qtd_PRs_aceitos.png'")

        # Mostra o gr√°fico no PyCharm Professional (no Community talvez tenha que baixar plugin)
        plt.show()

        # Fecha a figura para liberar mem√≥ria
        plt.close()

    except Exception as e:
        print(f"\nErro ao gerar o gr√°fico: {str(e)}")
        import traceback
        print(traceback.format_exc())

    # RQ 03
    print("\nRQ 03. Sistemas populares lan√ßam releases com frequ√™ncia?")
    releases_mean = df['releases'].apply(lambda x: x['totalCount']).mean()
    releases_median = df['releases'].apply(lambda x: x['totalCount']).median()
    print(f"M√©dia de releases: {releases_mean:.2f}")
    print(f"Mediana de releases: {releases_median:.2f}")

    # RQ 04
    print("\nRQ 04. Sistemas populares s√£o atualizados com frequ√™ncia?")
    update_mean = df['days_since_update'].mean()
    update_median = df['days_since_update'].median()
    print(f"M√©dia de dias desde √∫ltima atualiza√ß√£o: {update_mean:.2f}")
    print(f"Mediana de dias desde √∫ltima atualiza√ß√£o: {update_median:.2f}")

    # RQ 05
    print("\nRQ 05. Sistemas populares s√£o escritos nas linguagens mais populares?")
    try:
        # Configurar o matplotlib especificamente para o PyCharm, IDE usada pelo grupo
        import matplotlib
        matplotlib.use('module://backend_interagg')  # Backend espec√≠fico para IDEs
        import matplotlib.pyplot as plt
        import seaborn as sns

        # Limpa os None e prepara os dados
        languages_count = df['language'].replace('None', pd.NA).dropna().value_counts().head(10)

        print("\nTop 10 linguagens mais usadas nos reposit√≥rios populares:")
        print(languages_count)

        # Cria nova figura com tamanho espec√≠fico para o PyCharm, IDE utilizada
        plt.figure(figsize=(10, 6), dpi=100)

        # Cria o plot usando Seaborn
        ax = sns.barplot(
            x=languages_count.index,
            y=languages_count.values,
            hue=languages_count.index,
            palette='husl',
            legend=False
        )

        # Configura o gr√°fico
        plt.title('Top 10 Linguagens de Programa√ß√£o mais Populares no GitHub')
        plt.xlabel('Linguagens')
        plt.ylabel('N√∫mero de Reposit√≥rios')

        # Rotaciona labels
        plt.xticks(rotation=45, ha='right')

        # Adiciona valores nas barras
        for i, v in enumerate(languages_count.values):
            ax.text(i, v, str(int(v)), ha='center', va='bottom')

        # Ajusta layout
        plt.tight_layout()

        # Salva o gr√°fico
        plt.savefig(os.path.join(output_dir, 'top_languages.png'), dpi=300, bbox_inches='tight')
        print("\nGr√°fico salvo como 'top_languages.png'")

        # Mostra o gr√°fico no PyCharm Professional (no Community talvez tenha que baixar plugin)
        plt.show()

        # Fecha a figura para liberar mem√≥ria
        plt.close()

    except Exception as e:
        print(f"\nErro ao gerar o gr√°fico: {str(e)}")
        import traceback
        print(traceback.format_exc())

    # RQ 06
    print("\nRQ 06. Sistemas populares possuem um alto percentual de issues fechadas?")
    issues_ratio_mean = df['issues_closed_ratio'].mean() * 100
    issues_ratio_median = df['issues_closed_ratio'].median() * 100
    print(f"M√©dia do percentual de issues fechadas: {issues_ratio_mean:.2f}%")
    print(f"Mediana do percentual de issues fechadas: {issues_ratio_median:.2f}%")

    # RQ 07
    print("\nRQ 07. An√°lise por linguagem das principais m√©tricas:")
    top_languages = languages_count.index.tolist()

    metrics_by_language = df[df['language'].isin(top_languages)].groupby('language').agg({
        'pullRequests': lambda x: pd.Series([i['totalCount'] for i in x]).mean(),
        'releases': lambda x: pd.Series([i['totalCount'] for i in x]).mean(),
        'days_since_update': 'mean'
    }).round(2)

    print("\nM√©dia de m√©tricas por linguagem popular:")
    print(metrics_by_language)


def main():
    """
        Fun√ß√£o principal que coordena todo o processo de coleta, an√°lise e gera√ß√£o de relat√≥rio.

        Fluxo de execu√ß√£o:
        1. Inicializa conex√£o com API do GitHub
        2. Coleta dados dos reposit√≥rios mais populares
        3. Processa e analisa os dados coletados
        4. Gera relat√≥rio com visualiza√ß√µes e m√©tricas
        5. Salva resultados em arquivo CSV

        Raises:
            ValueError: Se nenhum dado for coletado
            Exception: Para outros erros durante a execu√ß√£o
    """
    try:
        print("\nüîπ Iniciando coleta de dados...")
        collector = GitHubDataCollector(TOKEN)
        repos_data = collector.get_top_repos(1000)

        if not repos_data:
            raise ValueError("‚ùå Nenhum dado foi coletado")

        print(f"\n‚úÖ Total de reposit√≥rios coletados: {len(repos_data)}")

        print("\nüîπ Analisando os dados...")
        df = analyze_data(repos_data)

        print("\nGerando relat√≥rio...")
        generate_research_report(df)

        df.to_csv(os.path.join(output_dir, 'github_analysis.csv'), index=False)
        print("\n‚úÖ Dados salvos em 'github_analysis.csv'")

    except Exception as e:
        print(f"‚ùå ERRO: {str(e)}")


if __name__ == "__main__":
    main()
